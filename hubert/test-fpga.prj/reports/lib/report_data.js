var areaJSON={"columns":["", "ALUTs", "FFs", "RAMs", "DSPs", "MLABs", "Details"], "debug_enabled":"true", "type":"module", "total_percent":[19.2043, 13.795, 6.89904, 4.77002, 1.04167], "total":[18763, 22168, 28, 2, 170], "name":"System", "max_resources":[160660, 321320, 587, 192, 8033], "children":[{"name":"add", "compute_units":1, "type":"function", "total_percent":[19.2043, 13.795, 6.89904, 4.77002, 1.04167], "total_kernel_resources":[18763, 22168, 28, 2, 170], "details":[{"type":"text", "text":"Number of compute units: 1"}, {"type":"brief", "text":"1 compute unit."}], "children":[{"name":"Component call", "type":"resource", "data":[0, 0, 0, 0, 0], "details":[{"type":"text", "text":"Stream implemented 192 bits wide with a buffer size of 0 elements."}, {"type":"brief", "text":"192b wide with 0 elements."}]}, {"name":"Component return", "type":"resource", "data":[0, 0, 0, 0, 0], "details":[{"type":"text", "text":"Stream implemented 1 bit wide with a buffer size of 0 elements."}, {"type":"brief", "text":"1b wide with 0 elements."}]}, {"name":"Variable: \\n - \'j\' (tensorXL.cpp:169)", "type":"resource", "data":[45, 198, 0, 0, 0], "debug":[[{"filename":"tensorXL.cpp", "line":169}]], "details":[{"type":"text", "text":"Type: Register"}, {"type":"text", "text":"1 register of width 32 bits and depth 3", "details":[{"type":"text", "text":" Depth was increased by a factor of 103 due to a loop initiation interval of 103."}]}, {"type":"brief", "text":"Register,\\n1 reg, 32 width by 3 depth"}]}, {"name":"Variable: \\n - \'j\' (tensorXL.cpp:366)", "type":"resource", "data":[45, 198, 0, 0, 0], "debug":[[{"filename":"tensorXL.cpp", "line":366}]], "details":[{"type":"text", "text":"Type: Register"}, {"type":"text", "text":"1 register of width 32 bits and depth 3", "details":[{"type":"text", "text":" Depth was increased by a factor of 104 due to a loop initiation interval of 104."}]}, {"type":"brief", "text":"Register,\\n1 reg, 32 width by 3 depth"}]}, {"name":"add.B1.start", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[252, 971, 0, 0, 12], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[204, 406, 0, 0, 12]}, {"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027", "type":"resource", "data":[38, 360, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":1112}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]]}, {"name":"tensorXL.cpp:142", "type":"resource", "data":[5, 37, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":142}]]}, {"name":"tensorXL.cpp:143", "type":"resource", "data":[5, 37, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":143}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:976 > \\ntensorXL.cpp:930", "type":"resource", "data":[0, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":976}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":930}]]}, {"name":"tensorXL.cpp:170", "type":"resource", "data":[0, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]]}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:947", "type":"resource", "data":[0, 1, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":947}]]}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:960 > \\ntensorXL.cpp:1027", "type":"resource", "data":[0, 96, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":960}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]]}]}, {"name":"Feedback", "type":"resource", "data":[7, 2, 0, 0, 0], "details":[{"type":"brief", "text":"Loop-carried dependencies"}, {"type":"text", "text":"Resources for loop-carried dependencies. To reduce this area:", "details":[{"type":"text", "text":"reduce number and size of loop-carried variables"}]}], "children":[{"name":"tensorXL.cpp:134", "type":"resource", "data":[7, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]]}]}, {"name":"Computation", "type":"resource", "children":[{"name":"No Source Line", "type":"resource", "data":[2, 1, 0, 0, 0], "debug":[[{"filename":"", "line":0}]], "children":[{"name":"1-bit And", "type":"resource", "count":2, "data":[2, 1, 0, 0, 0]}]}, {"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027", "type":"resource", "data":[1426, 1206, 0, 0, 40], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":1112}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":6, "data":[1374, 1206, 0, 0, 40], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:140 > tensorXL.cpp:1112", "type":"resource", "data":[75, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1112}]], "children":[{"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":2, "data":[22, 0, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:976 > \\ntensorXL.cpp:917", "type":"resource", "data":[37, 1, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":976}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":917}]], "children":[{"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[11, 1, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":1, "data":[26, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:976 > \\ntensorXL.cpp:930", "type":"resource", "data":[314, 222, 0, 0, 7], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":976}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":930}]], "children":[{"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[11, 1, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":1, "data":[251, 221, 0, 0, 7], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:960 > \\ntensorXL.cpp:1027", "type":"resource", "data":[528, 442, 0, 0, 14], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":960}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":1, "data":[26, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":2, "data":[502, 442, 0, 0, 14], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:947", "type":"resource", "data":[185, 161, 0, 0, 6], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":947}]], "children":[{"name":"Load", "type":"resource", "count":1, "data":[185, 161, 0, 0, 6], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:134", "type":"resource", "data":[1, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "children":[{"name":"Stream Read", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:142", "type":"resource", "data":[16, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":142}]], "children":[{"name":"32-bit Select", "type":"resource", "count":1, "data":[16, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:143", "type":"resource", "data":[42, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":143}]], "children":[{"name":"32-bit Select", "type":"resource", "count":2, "data":[42, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:157", "type":"resource", "data":[24, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":157}]], "children":[{"name":"1-bit And", "type":"resource", "count":2, "data":[2, 0, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":2, "data":[22, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:170", "type":"resource", "data":[11, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]], "children":[{"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[11, 0, 0, 0, 0]}], "replace_name":"true"}]}]}, {"name":"add.B12", "type":"basicblock", "children":[{"name":"Feedback", "type":"resource", "data":[5, 8, 0, 0, 0], "details":[{"type":"brief", "text":"Loop-carried dependencies"}, {"type":"text", "text":"Resources for loop-carried dependencies. To reduce this area:", "details":[{"type":"text", "text":"reduce number and size of loop-carried variables"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[5, 8, 0, 0, 0]}]}, {"name":"Computation", "type":"resource", "children":[{"name":"tensorXL.cpp:177", "type":"resource", "data":[5, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":177}]], "children":[{"name":"Stream Write", "type":"resource", "count":1, "data":[5, 2, 0, 0, 0]}], "replace_name":"true"}]}]}, {"name":"add.B4", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[18, 196, 0, 0, 0], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[17, 33, 0, 0, 0]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:366", "type":"resource", "data":[0, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":366}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:367", "type":"resource", "data":[0, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":367}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:367 > \\ntensorXL.cpp:1027", "type":"resource", "data":[0, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":367}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369", "type":"resource", "data":[0, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:932", "type":"resource", "data":[1, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:960", "type":"resource", "data":[0, 1, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":960}]]}]}, {"name":"Computation", "type":"resource", "children":[{"name":"tensorXL.cpp:159 > tensorXL.cpp:367 > \\ntensorXL.cpp:1027", "type":"resource", "data":[52, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":367}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369 > \\ntensorXL.cpp:1037", "type":"resource", "data":[26, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":369}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "children":[{"name":"32-bit Select", "type":"resource", "count":1, "data":[26, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:960", "type":"resource", "data":[35, 1, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":960}]], "children":[{"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369", "type":"resource", "data":[12, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]], "children":[{"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[11, 0, 0, 0, 0]}], "replace_name":"true"}]}]}, {"name":"add.B5", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[896, 1465, 9, 0, 4], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[892, 1401, 9, 0, 4]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369 > \\ntensorXL.cpp:1037", "type":"resource", "data":[4, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":369}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]]}]}, {"name":"Feedback", "type":"resource", "data":[457, 1083, 0, 0, 1], "details":[{"type":"brief", "text":"Loop-carried dependencies"}, {"type":"text", "text":"Resources for loop-carried dependencies. To reduce this area:", "details":[{"type":"text", "text":"reduce number and size of loop-carried variables"}]}], "children":[{"name":"tensorXL.cpp:159 > tensorXL.cpp:366", "type":"resource", "data":[22, 33, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":366}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:367", "type":"resource", "data":[66, 238, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":367}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369", "type":"resource", "data":[133, 287, 0, 0, 1], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369 > \\ntensorXL.cpp:1037", "type":"resource", "data":[202, 504, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":369}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:962", "type":"resource", "data":[34, 21, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":962}]]}]}, {"name":"Cluster logic", "type":"resource", "data":[8, 6, 0, 0, 3], "details":[{"type":"brief", "text":"Logic required to efficiently support sets of operations that do not stall"}, {"type":"text", "text":"Logic required to efficiently support sets of operations that do not stall. This area cannot be affected directly."}]}, {"name":"Computation", "type":"resource", "children":[{"name":"No Source Line", "type":"resource", "data":[1, 0, 0, 0, 0], "debug":[[{"filename":"", "line":0}]], "children":[{"name":"1-bit Xor", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}]}, {"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027", "type":"resource", "data":[4, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":1112}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"FFwd Destination", "type":"resource", "count":7, "data":[4, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369 > \\ntensorXL.cpp:1037", "type":"resource", "data":[581, 442, 0, 0, 14], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":369}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "children":[{"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":3, "data":[78, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":2, "data":[502, 442, 0, 0, 14], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:930 > tensorXL.cpp:1027", "type":"resource", "data":[26, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":930}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":1, "data":[26, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:917", "type":"resource", "data":[37, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":917}]], "children":[{"name":"1-bit And", "type":"resource", "count":2, "data":[2, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:930", "type":"resource", "data":[71, 3, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":930}]], "children":[{"name":"1-bit And", "type":"resource", "count":1, "data":[1, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":2, "data":[70, 2, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:932", "type":"resource", "data":[335, 254, 0, 0, 7], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]], "children":[{"name":"1-bit Select", "type":"resource", "count":1, "data":[1, 1, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":1, "data":[32, 32, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":1, "data":[251, 221, 0, 0, 7], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}, {"name":"Select", "type":"resource", "count":1, "data":[51, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:949", "type":"resource", "data":[37, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":949}]], "children":[{"name":"1-bit And", "type":"resource", "count":2, "data":[2, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:960", "type":"resource", "data":[37, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":960}]], "children":[{"name":"1-bit And", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:962", "type":"resource", "data":[156, 336, 0, 0, 5], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":371}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":962}]], "children":[{"name":"Select", "type":"resource", "count":1, "data":[64, 64, 0, 0, 0]}, {"name":"Store", "type":"resource", "count":1, "data":[92, 272, 0, 0, 5], "details":[{"type":"text", "text":"Store uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:369", "type":"resource", "data":[68, 8, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]], "children":[{"name":"1-bit And", "type":"resource", "count":3, "data":[2, 1, 0, 0, 0]}, {"name":"1-bit Or", "type":"resource", "count":5, "data":[3, 2, 0, 0, 0]}, {"name":"17-bit Select", "type":"resource", "count":1, "data":[14, 0, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}, {"name":"FFwd Destination", "type":"resource", "count":5, "data":[8, 0, 0, 0, 0]}, {"name":"Iteration Initiation", "type":"resource", "count":1, "data":[6, 4, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:371", "type":"resource", "data":[0, 0, 0, 1, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":371}]], "children":[{"name":"32-bit Floating-point Add", "type":"resource", "count":1, "data":[0, 0, 0, 1, 0]}], "replace_name":"true"}]}]}, {"name":"add.B6", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[36, 128, 0, 0, 0], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[32, 64, 0, 0, 0]}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:367 > \\ntensorXL.cpp:1027", "type":"resource", "data":[4, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":367}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]]}]}, {"name":"Computation", "type":"resource", "children":[{"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027", "type":"resource", "data":[2, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":1112}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"FFwd Destination", "type":"resource", "count":1, "data":[2, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:367 > \\ntensorXL.cpp:1027", "type":"resource", "data":[78, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":367}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":3, "data":[78, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:159 > tensorXL.cpp:367", "type":"resource", "data":[38, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":159}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":367}]], "children":[{"name":"1-bit And", "type":"resource", "count":1, "data":[1, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}, {"name":"FFwd Destination", "type":"resource", "count":1, "data":[2, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:170", "type":"resource", "data":[2, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]], "children":[{"name":"FFwd Destination", "type":"resource", "count":1, "data":[2, 0, 0, 0, 0]}], "replace_name":"true"}]}]}, {"name":"add.B7", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[184, 4015, 1, 0, 0], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[183, 3788, 1, 0, 0]}, {"name":"tensorXL.cpp:169", "type":"resource", "data":[0, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":169}]]}, {"name":"tensorXL.cpp:170", "type":"resource", "data":[0, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]]}, {"name":"tensorXL.cpp:170 > tensorXL.cpp:1027", "type":"resource", "data":[0, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":170}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]]}, {"name":"tensorXL.cpp:172", "type":"resource", "data":[0, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]]}, {"name":"tensorXL.cpp:174", "type":"resource", "data":[0, 32, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":174}]]}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:932", "type":"resource", "data":[1, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]]}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:960", "type":"resource", "data":[0, 1, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":960}]]}]}, {"name":"Cluster logic", "type":"resource", "data":[12, 10, 1, 0, 0], "details":[{"type":"brief", "text":"Logic required to efficiently support sets of operations that do not stall"}, {"type":"text", "text":"Logic required to efficiently support sets of operations that do not stall. This area cannot be affected directly."}]}, {"name":"Computation", "type":"resource", "children":[{"name":"tensorXL.cpp:170 > tensorXL.cpp:1027", "type":"resource", "data":[52, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":170}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:172 > tensorXL.cpp:1037", "type":"resource", "data":[26, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":172}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "children":[{"name":"32-bit Select", "type":"resource", "count":1, "data":[26, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:960", "type":"resource", "data":[35, 1, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":960}]], "children":[{"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:172", "type":"resource", "data":[12, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]], "children":[{"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[11, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174", "type":"resource", "data":[2865, 528, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":174}]], "children":[{"name":"32-bit Unsigned Integer Remainder", "type":"resource", "count":1, "data":[2865, 528, 0, 0, 0], "details":[{"type":"text", "text":"Implemented using inlined soft-IP."}]}], "replace_name":"true"}]}]}, {"name":"add.B8", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[3746, 6842, 17, 0, 7], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[3742, 6778, 17, 0, 7]}, {"name":"tensorXL.cpp:172 > tensorXL.cpp:1037", "type":"resource", "data":[4, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":172}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]]}]}, {"name":"Feedback", "type":"resource", "data":[444, 1076, 0, 0, 1], "details":[{"type":"brief", "text":"Loop-carried dependencies"}, {"type":"text", "text":"Resources for loop-carried dependencies. To reduce this area:", "details":[{"type":"text", "text":"reduce number and size of loop-carried variables"}]}], "children":[{"name":"tensorXL.cpp:169", "type":"resource", "data":[22, 33, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":169}]]}, {"name":"tensorXL.cpp:170", "type":"resource", "data":[66, 238, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]]}, {"name":"tensorXL.cpp:172", "type":"resource", "data":[133, 287, 0, 0, 1], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]]}, {"name":"tensorXL.cpp:172 > tensorXL.cpp:1037", "type":"resource", "data":[202, 504, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":172}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]]}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:962", "type":"resource", "data":[21, 14, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":962}]]}]}, {"name":"Cluster logic", "type":"resource", "data":[8, 6, 0, 0, 2], "details":[{"type":"brief", "text":"Logic required to efficiently support sets of operations that do not stall"}, {"type":"text", "text":"Logic required to efficiently support sets of operations that do not stall. This area cannot be affected directly."}]}, {"name":"Computation", "type":"resource", "children":[{"name":"No Source Line", "type":"resource", "data":[1, 0, 0, 0, 0], "debug":[[{"filename":"", "line":0}]], "children":[{"name":"1-bit Xor", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}]}, {"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027", "type":"resource", "data":[6, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":1112}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"FFwd Destination", "type":"resource", "count":13, "data":[6, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:172 > tensorXL.cpp:1037", "type":"resource", "data":[581, 442, 0, 0, 14], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":172}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "children":[{"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":3, "data":[78, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":2, "data":[502, 442, 0, 0, 14], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:930 > \\ntensorXL.cpp:1027", "type":"resource", "data":[554, 442, 0, 0, 14], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":930}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":2, "data":[502, 442, 0, 0, 14], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:917", "type":"resource", "data":[74, 4, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":917}]], "children":[{"name":"1-bit And", "type":"resource", "count":4, "data":[4, 2, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":2, "data":[70, 2, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:930", "type":"resource", "data":[142, 5, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":930}]], "children":[{"name":"1-bit And", "type":"resource", "count":2, "data":[2, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":4, "data":[140, 4, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:932", "type":"resource", "data":[658, 444, 0, 0, 14], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]], "children":[{"name":"1-bit Select", "type":"resource", "count":2, "data":[2, 2, 0, 0, 0]}, {"name":"32-bit Select", "type":"resource", "count":2, "data":[52, 0, 0, 0, 0]}, {"name":"Load", "type":"resource", "count":2, "data":[502, 442, 0, 0, 14], "details":[{"type":"text", "text":"Load uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}, {"name":"Select", "type":"resource", "count":2, "data":[102, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:949", "type":"resource", "data":[37, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":949}]], "children":[{"name":"1-bit And", "type":"resource", "count":2, "data":[2, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:960", "type":"resource", "data":[37, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":960}]], "children":[{"name":"1-bit And", "type":"resource", "count":1, "data":[1, 0, 0, 0, 0]}, {"name":"1-bit Or", "type":"resource", "count":1, "data":[1, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174 > tensorXL.cpp:962", "type":"resource", "data":[156, 336, 0, 0, 5], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":174}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":962}]], "children":[{"name":"Select", "type":"resource", "count":1, "data":[64, 64, 0, 0, 0]}, {"name":"Store", "type":"resource", "count":1, "data":[92, 272, 0, 0, 5], "details":[{"type":"text", "text":"Store uses a Pipelined LSU"}, {"type":"brief", "text":"Pipelined LSU"}]}], "replace_name":"true"}, {"name":"tensorXL.cpp:172", "type":"resource", "data":[78, 12, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]], "children":[{"name":"1-bit And", "type":"resource", "count":3, "data":[2, 1, 0, 0, 0]}, {"name":"1-bit Or", "type":"resource", "count":5, "data":[3, 2, 0, 0, 0]}, {"name":"17-bit Select", "type":"resource", "count":1, "data":[14, 0, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}, {"name":"FFwd Destination", "type":"resource", "count":8, "data":[14, 0, 0, 0, 0]}, {"name":"Iteration Initiation", "type":"resource", "count":1, "data":[10, 8, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:174", "type":"resource", "data":[2866, 529, 0, 1, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":174}]], "children":[{"name":"32-bit Floating-point Add", "type":"resource", "count":1, "data":[0, 0, 0, 1, 0]}, {"name":"32-bit Unsigned Integer Remainder", "type":"resource", "count":1, "data":[2866, 529, 0, 0, 0], "details":[{"type":"text", "text":"Implemented using inlined soft-IP."}]}], "replace_name":"true"}]}]}, {"name":"add.B9", "type":"basicblock", "children":[{"name":"State", "type":"resource", "data":[36, 128, 0, 0, 0], "details":[{"type":"brief", "text":"Live values and control logic"}, {"type":"text", "text":"Resources for live values and control logic. To reduce this area:", "details":[{"type":"text", "text":"reduce size of local variables"}, {"type":"text", "text":"reduce scope of local variables, localizing them as much as possible"}, {"type":"text", "text":"reduce number of nested loops"}]}], "children":[{"name":"No Source Line", "type":"resource", "data":[32, 64, 0, 0, 0]}, {"name":"tensorXL.cpp:170 > tensorXL.cpp:1027", "type":"resource", "data":[4, 64, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":170}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]]}]}, {"name":"Computation", "type":"resource", "children":[{"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027", "type":"resource", "data":[2, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":140}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":1112}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"FFwd Destination", "type":"resource", "count":1, "data":[2, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:170 > tensorXL.cpp:1027", "type":"resource", "data":[78, 0, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":170}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "children":[{"name":"32-bit Select", "type":"resource", "count":3, "data":[78, 0, 0, 0, 0]}], "replace_name":"true"}, {"name":"tensorXL.cpp:170", "type":"resource", "data":[40, 2, 0, 0, 0], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]], "children":[{"name":"1-bit And", "type":"resource", "count":1, "data":[1, 1, 0, 0, 0]}, {"name":"32-bit Integer Compare", "type":"resource", "count":1, "data":[35, 1, 0, 0, 0]}, {"name":"FFwd Destination", "type":"resource", "count":2, "data":[4, 0, 0, 0, 0]}], "replace_name":"true"}]}]}]}]};
var area_srcJSON={"children":[{"children":[{"data":[941,2191,1,0,7],"details":[{"text":"Feedback+Cluster logic","type":"brief"}],"name":"Data control overhead","type":"resource"},{"data":[0,0,0,0,0],"details":[{"text":"Stream implemented 192 bits wide with a buffer size of 0 elements.","type":"text"},{"text":"192b wide with 0 elements.","type":"brief"}],"name":"Component call","type":"resource"},{"data":[0,0,0,0,0],"details":[{"text":"Stream implemented 1 bit wide with a buffer size of 0 elements.","type":"text"},{"text":"1b wide with 0 elements.","type":"brief"}],"name":"Component return","type":"resource"},{"data":[45,198,0,0,0],"details":[{"text":"Type: Register","type":"text"},{"details":[{"text":" Depth was increased by a factor of 103 due to a loop initiation interval of 103.","type":"text"}],"text":"1 register of width 32 bits and depth 3","type":"text"},{"text":"Register,\\n1 reg, 32 width by 3 depth","type":"brief"}],"name":"Variable: \\n - \'j\' (tensorXL.cpp:169)","type":"resource"},{"data":[45,198,0,0,0],"details":[{"text":"Type: Register","type":"text"},{"details":[{"text":" Depth was increased by a factor of 104 due to a loop initiation interval of 104.","type":"text"}],"text":"1 register of width 32 bits and depth 3","type":"text"},{"text":"Register,\\n1 reg, 32 width by 3 depth","type":"brief"}],"name":"Variable: \\n - \'j\' (tensorXL.cpp:366)","type":"resource"},{"children":[{"count":7,"data":[5102,12534,27,0,23],"debug":[[{"filename":"","line":0}]],"name":"State","type":"resource"},{"count":2,"data":[2,1,0,0,0],"debug":[[{"filename":"","line":0}]],"name":"1-bit And","type":"resource"},{"count":2,"data":[2,0,0,0,0],"debug":[[{"filename":"","line":0}]],"name":"1-bit Xor","type":"resource"}],"data":[5106,12535,27,0,23],"name":"No Source Line","type":"resource"},{"children":[{"children":[{"count":"1","data":[38,360,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":2,"data":[52,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"},{"count":6,"data":[1374,1206,0,0,40],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"Load","type":"resource"},{"count":22,"data":[14,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"140"}]],"name":"FFwd Destination","type":"resource"}],"data":[1478,1566,0,0,40],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":140},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":1112},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1027}]],"name":"tensorXL.cpp:140 > tensorXL.cpp:1112 > \\ntensorXL.cpp:1027","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[1,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"1-bit Or","type":"resource"},{"count":2,"data":[22,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":2,"data":[52,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"}],"data":[75,0,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":140},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1112}]],"name":"tensorXL.cpp:140 > tensorXL.cpp:1112","replace_name":true,"type":"resource"}],"data":[1553,1566,0,0,40],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":140}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp:140","type":"resource"},{"children":[{"count":"1","data":[5,37,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":1,"data":[16,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"}],"data":[21,37,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":142}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:142","type":"resource"},{"children":[{"count":"1","data":[5,37,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":2,"data":[42,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"}],"data":[47,37,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":143}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:143","type":"resource"},{"children":[{"children":[{"count":"1","data":[0,32,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":1,"data":[11,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":2,"data":[52,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"},{"count":1,"data":[251,221,0,0,7],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"Load","type":"resource"}],"data":[314,254,0,0,7],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":976},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":930}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:976 > \\ntensorXL.cpp:930","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[11,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":1,"data":[26,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"}],"data":[37,1,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":976},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":917}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:976 > \\ntensorXL.cpp:917","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[0,32,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"}],"data":[0,32,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":366}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:366","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[0,32,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"},{"count":1,"data":[1,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[35,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":1,"data":[2,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"FFwd Destination","type":"resource"}],"data":[38,34,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":367}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:367","replace_name":true,"type":"resource"},{"children":[{"count":2,"data":[4,128,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"},{"count":5,"data":[130,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Select","type":"resource"}],"data":[134,128,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":367},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1027}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:367 > \\ntensorXL.cpp:1027","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[0,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"},{"count":6,"data":[4,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit Or","type":"resource"},{"count":2,"data":[46,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":3,"data":[2,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[14,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"17-bit Select","type":"resource"},{"count":5,"data":[8,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"FFwd Destination","type":"resource"},{"count":1,"data":[6,4,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"Iteration Initiation","type":"resource"}],"data":[80,10,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":369}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:369","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[1,32,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"},{"count":1,"data":[1,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit Select","type":"resource"},{"count":1,"data":[32,32,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Select","type":"resource"},{"count":1,"data":[251,221,0,0,7],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"Load","type":"resource"},{"count":1,"data":[51,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"Select","type":"resource"}],"data":[336,286,0,0,7],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":932}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:932","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[0,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"},{"count":2,"data":[70,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":1,"data":[1,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[1,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit Or","type":"resource"}],"data":[72,4,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":960}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:960","replace_name":true,"type":"resource"},{"children":[{"count":4,"data":[104,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Select","type":"resource"},{"count":"1","data":[4,64,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"State","type":"resource"},{"count":1,"data":[1,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit Or","type":"resource"},{"count":2,"data":[502,442,0,0,14],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"Load","type":"resource"}],"data":[611,506,0,0,14],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":369},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1037}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:369 > \\ntensorXL.cpp:1037","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[26,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Select","type":"resource"}],"data":[26,0,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":930},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1027}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:930 > tensorXL.cpp:1027","replace_name":true,"type":"resource"},{"children":[{"count":2,"data":[2,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[35,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[37,2,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":917}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:917","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[1,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit And","type":"resource"},{"count":2,"data":[70,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[71,3,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":930}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:930","replace_name":true,"type":"resource"},{"children":[{"count":2,"data":[2,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[35,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[37,2,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":949}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:949","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[64,64,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"Select","type":"resource"},{"count":1,"data":[92,272,0,0,5],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"Store","type":"resource"}],"data":[156,336,0,0,5],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":371},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":962}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371 > \\ntensorXL.cpp:962","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[0,0,0,1,0],"debug":[[{"filename":"tensorXL.cpp","line":"159"}]],"name":"32-bit Floating-point Add","type":"resource"}],"data":[0,0,0,1,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":371}]],"name":"tensorXL.cpp:159 > tensorXL.cpp:371","replace_name":true,"type":"resource"}],"data":[1949,1598,0,1,33],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":159}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp:159","type":"resource"},{"children":[{"count":2,"data":[0,34,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":2,"data":[46,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":3,"data":[6,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"FFwd Destination","type":"resource"},{"count":1,"data":[1,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"1-bit And","type":"resource"}],"data":[53,36,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":170}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:170","type":"resource"},{"children":[{"children":[{"count":"1","data":[0,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":1,"data":[185,161,0,0,6],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"Load","type":"resource"}],"data":[185,162,0,0,6],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":947}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:947","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[0,96,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":1,"data":[26,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"},{"count":2,"data":[502,442,0,0,14],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"Load","type":"resource"}],"data":[528,538,0,0,14],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":960},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1027}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:960 > \\ntensorXL.cpp:1027","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[1,64,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"State","type":"resource"},{"count":2,"data":[2,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"1-bit Select","type":"resource"},{"count":2,"data":[52,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"32-bit Select","type":"resource"},{"count":2,"data":[502,442,0,0,14],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"Load","type":"resource"},{"count":2,"data":[102,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"Select","type":"resource"}],"data":[659,508,0,0,14],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":932}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:932","replace_name":true,"type":"resource"},{"children":[{"count":"1","data":[0,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"State","type":"resource"},{"count":2,"data":[70,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":1,"data":[1,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[1,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"1-bit Or","type":"resource"}],"data":[72,4,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":960}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:960","replace_name":true,"type":"resource"},{"children":[{"count":2,"data":[52,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"32-bit Select","type":"resource"},{"count":2,"data":[502,442,0,0,14],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"Load","type":"resource"}],"data":[554,442,0,0,14],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":930},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1027}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:930 > \\ntensorXL.cpp:1027","replace_name":true,"type":"resource"},{"children":[{"count":4,"data":[4,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"1-bit And","type":"resource"},{"count":2,"data":[70,2,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[74,4,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":917}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:917","replace_name":true,"type":"resource"},{"children":[{"count":2,"data":[2,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"1-bit And","type":"resource"},{"count":4,"data":[140,4,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[142,5,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":930}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:930","replace_name":true,"type":"resource"},{"children":[{"count":2,"data":[2,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[35,1,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[37,2,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":949}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:949","replace_name":true,"type":"resource"},{"children":[{"count":1,"data":[64,64,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"Select","type":"resource"},{"count":1,"data":[92,272,0,0,5],"debug":[[{"filename":"tensorXL.cpp","line":"174"}]],"name":"Store","type":"resource"}],"data":[156,336,0,0,5],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":962}]],"name":"tensorXL.cpp:174 > tensorXL.cpp:962","replace_name":true,"type":"resource"}],"data":[2407,2001,0,0,53],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":174}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp:174","type":"resource"},{"children":[{"count":1,"data":[1,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"Stream Read","type":"resource"}],"data":[1,0,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":134}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:134","replace_name":"true","type":"resource"},{"children":[{"count":2,"data":[2,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"1-bit And","type":"resource"},{"count":2,"data":[22,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Integer Compare","type":"resource"}],"data":[24,0,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":157}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:157","replace_name":"true","type":"resource"},{"children":[{"count":1,"data":[5,2,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"Stream Write","type":"resource"}],"data":[5,2,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":177}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:177","replace_name":"true","type":"resource"},{"children":[{"count":"1","data":[0,32,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"State","type":"resource"}],"data":[0,32,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":169}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:169","type":"resource"},{"children":[{"children":[{"count":2,"data":[4,128,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":5,"data":[130,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"}],"data":[134,128,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":170},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1027}]],"name":"tensorXL.cpp:170 > tensorXL.cpp:1027","replace_name":true,"type":"resource"}],"data":[134,128,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":170}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp:170","type":"resource"},{"children":[{"count":"1","data":[0,2,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":6,"data":[4,2,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"1-bit Or","type":"resource"},{"count":2,"data":[46,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Integer Compare","type":"resource"},{"count":3,"data":[2,1,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"1-bit And","type":"resource"},{"count":1,"data":[14,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"17-bit Select","type":"resource"},{"count":8,"data":[14,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"FFwd Destination","type":"resource"},{"count":1,"data":[10,8,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"Iteration Initiation","type":"resource"}],"data":[90,14,0,0,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":172}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:172","type":"resource"},{"children":[{"count":"1","data":[0,32,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"State","type":"resource"},{"count":2,"data":[5731,1057,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Unsigned Integer Remainder","type":"resource"},{"count":1,"data":[0,0,0,1,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp"}]],"name":"32-bit Floating-point Add","type":"resource"}],"data":[5731,1089,0,1,0],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":174}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp:174","type":"resource"},{"children":[{"children":[{"count":4,"data":[104,0,0,0,0],"debug":[[{"filename":"C","line":"\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp"}]],"name":"32-bit Select","type":"resource"},{"count":"1","data":[4,64,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"172"}]],"name":"State","type":"resource"},{"count":1,"data":[1,0,0,0,0],"debug":[[{"filename":"tensorXL.cpp","line":"172"}]],"name":"1-bit Or","type":"resource"},{"count":2,"data":[502,442,0,0,14],"debug":[[{"filename":"tensorXL.cpp","line":"172"}]],"name":"Load","type":"resource"}],"data":[611,506,0,0,14],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":172},{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp","line":1037}]],"name":"tensorXL.cpp:172 > tensorXL.cpp:1037","replace_name":true,"type":"resource"}],"data":[611,506,0,0,14],"debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp","line":172}]],"name":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp:172","replace_name":"true","type":"resource"}],"compute_units":1,"data":[18763,22168,28,2,170],"debug":[[{"filename":"tensorXL.cpp","line":169}]],"details":[{"text":"Number of compute units: 1","type":"text"},{"text":"1 compute unit.","type":"brief"}],"name":"add","total_kernel_resources":[18763,22168,28,2,170],"total_percent":[19.2043,13.795,6.89904,4.77002,1.04167],"type":"function"}],"columns":["","ALUTs","FFs","RAMs","DSPs","MLABs","Details"],"data":[18763,22168,28,2,170],"debug_enabled":"true","max_resources":[160660,321320,587,192,8033],"name":"System","total":[18763,22168,28,2,170],"total_percent":[19.2043,13.795,6.89904,4.77002,1.04167],"type":"module"};
var mavJSON={"nodes":[{"type":"component", "id":2, "name":"add", "children":[{"type":"bb", "id":3, "name":"add.B0.runOnce", "details":[{"type":"table", "Latency":"2"}]}, {"type":"bb", "id":4, "name":"add.B1.start", "children":[{"type":"inst", "id":16, "name":"Stream Read", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"table", "Width":"192 bits", "Depth":"0", "Stall-free":"No", "Start Cycle":"2", "Latency":"0", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":18, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"8 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"2", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":19, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"2", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":20, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"2", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":21, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"8 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"2", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":22, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"2", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":23, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"2", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":24, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":947}]], "details":[{"type":"table", "Width":"8 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"C", "Start Cycle":"34", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":25, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"C", "Start Cycle":"34", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":26, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"C", "Start Cycle":"34", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":27, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":930}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"34", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":41, "name":"Loop Input", "debug":[[{"filename":"", "line":0}]], "details":[{"type":"table", "Start Cycle":"0", "Latency":"1", "Loops To":"48"}]}, {"type":"inst", "id":42, "name":"End", "details":[{"type":"table", "Start Cycle":"66", "Latency":"1"}]}], "details":[{"type":"table", "Latency":"66", "II":"n/a", "Subloops":"Yes", "Pipelined":"No", "Fmax Bottlenecks":"No", "Loop Info":"Entry to loop. "}]}, {"type":"bb", "id":5, "name":"add.B2", "details":[{"type":"table", "Latency":"0"}]}, {"type":"bb", "id":6, "name":"add.B3", "details":[{"type":"table", "Latency":"0"}]}, {"type":"bb", "id":7, "name":"add.B4", "details":[{"type":"table", "Latency":"2", "II":"n/a", "Subloops":"Yes", "Pipelined":"No", "Fmax Bottlenecks":"No", "Loop Info":"Entry to loop. ", "Loops To":"9"}]}, {"type":"bb", "id":8, "name":"add.B5", "children":[{"type":"inst", "id":28, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"6", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":29, "name":"Store", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":962}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Stores to":"C", "Start Cycle":"45", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":30, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"76", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":31, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"76", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":43, "name":"Loop Input", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]], "details":[{"type":"table", "Start Cycle":"0", "Latency":"1", "Loops To":"44"}]}, {"type":"inst", "id":44, "name":"Loop End", "details":[{"type":"table", "Start Cycle":"109", "Latency":"1"}]}], "details":[{"type":"table", "Latency":"109", "II":"104", "Subloops":"No", "Pipelined":"Yes", "Fmax Bottlenecks":"No", "Loop Info":"Loop is pipelined with II of 104. See Loops Analysis for more information."}]}, {"type":"bb", "id":9, "name":"add.B6", "details":[{"type":"table", "Latency":"2", "II":"n/a", "Subloops":"Yes", "Pipelined":"No", "Fmax Bottlenecks":"No", "Loop Info":"Exit which branches back to loop. "}]}, {"type":"bb", "id":10, "name":"add.B7", "details":[{"type":"table", "Latency":"52", "II":"n/a", "Subloops":"Yes", "Pipelined":"No", "Fmax Bottlenecks":"No", "Loop Info":"Entry to loop. ", "Loops To":"12"}]}, {"type":"bb", "id":11, "name":"add.B8", "children":[{"type":"inst", "id":32, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"21", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":33, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1027}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"21", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":34, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"54", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":35, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":932}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"B", "Start Cycle":"54", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":36, "name":"Store", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":962}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Stores to":"C", "Start Cycle":"92", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":37, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"123", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":38, "name":"Load", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":1037}]], "details":[{"type":"table", "Width":"32 bits", "Type":"Pipelined", "Stall-free":"No", "Loads from":"A", "Start Cycle":"123", "Latency":"31", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":45, "name":"Loop Input", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]], "details":[{"type":"table", "Start Cycle":"0", "Latency":"1", "Loops To":"46"}]}, {"type":"inst", "id":46, "name":"Loop End", "details":[{"type":"table", "Start Cycle":"156", "Latency":"1"}]}], "details":[{"type":"table", "Latency":"156", "II":"103", "Subloops":"No", "Pipelined":"Yes", "Fmax Bottlenecks":"No", "Loop Info":"Loop is pipelined with II of 103. See Loops Analysis for more information."}]}, {"type":"bb", "id":12, "name":"add.B9", "details":[{"type":"table", "Latency":"2", "II":"n/a", "Subloops":"Yes", "Pipelined":"No", "Fmax Bottlenecks":"No", "Loop Info":"Exit which branches back to loop. "}]}, {"type":"bb", "id":13, "name":"add.B10", "details":[{"type":"table", "Latency":"0"}]}, {"type":"bb", "id":14, "name":"add.B11", "details":[{"type":"table", "Latency":"0"}]}, {"type":"bb", "id":15, "name":"add.B12", "children":[{"type":"inst", "id":39, "name":"Stream Write", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":177}]], "details":[{"type":"table", "Width":"1 bit", "Depth":"0", "Stall-free":"No", "Start Cycle":"1", "Latency":"0", "Reference":[{"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html"}]}]}]}, {"type":"inst", "id":47, "name":"Begin", "details":[{"type":"table", "Start Cycle":"0", "Latency":"1"}]}, {"type":"inst", "id":48, "name":"Loop End", "details":[{"type":"table", "Start Cycle":"1", "Latency":"1"}]}], "details":[{"type":"table", "Latency":"1", "II":"n/a", "Subloops":"Yes", "Pipelined":"No", "Fmax Bottlenecks":"No", "Loop Info":"Exit which branches back to loop. "}]}]}, {"type":"memtype", "id":1, "name":"System Memory", "children":[{"type":"memsys", "id":52, "name":"0", "details":[{"type":"table", "Number of banks":"1", "Arguments from add":"A, B, C"}]}]}, {"type":"stream", "id":17, "name":"call.add", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"table", "Width":"192 bits", "Depth":"0", "Bits per symbol":"192 bits", "Uses Packets":"No", "Uses Empty":"No", "First symbol in high order bits":"No", "Uses Valid":"Yes", "Ready Latency":"0"}]}, {"type":"stream", "id":40, "name":"return.add", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"table", "Width":"1 bit", "Depth":"0", "Bits per symbol":"1 bit", "Uses Packets":"No", "Uses Empty":"No", "First symbol in high order bits":"No", "Uses Ready":"Yes", "Ready Latency":"0"}]}, {"type":"interface", "id":49, "name":"A", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"table", "Stable":"No", "Data width":"64", "Address width":"64", "Address Space":"0", "Latency":"1", "ReadWrite Mode":"readwrite", "Maximum burst":"1", "Wait request":"0", "Alignment":"0", "Component":"add"}]}, {"type":"interface", "id":50, "name":"B", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"table", "Stable":"No", "Data width":"64", "Address width":"64", "Address Space":"0", "Latency":"1", "ReadWrite Mode":"readwrite", "Maximum burst":"1", "Wait request":"0", "Alignment":"0", "Component":"add"}]}, {"type":"interface", "id":51, "name":"C", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"table", "Stable":"No", "Data width":"64", "Address width":"64", "Address Space":"0", "Latency":"1", "ReadWrite Mode":"readwrite", "Maximum burst":"1", "Wait request":"0", "Alignment":"0", "Component":"add"}]}], "links":[{"from":17, "to":16}, {"from":39, "to":40}, {"from":49, "to":16}, {"from":50, "to":16}, {"from":51, "to":16}, {"from":48, "to":41}, {"from":3, "to":41}, {"from":16, "to":42}, {"from":18, "to":42}, {"from":19, "to":42}, {"from":20, "to":42}, {"from":21, "to":42}, {"from":22, "to":42}, {"from":23, "to":42}, {"from":24, "to":42}, {"from":25, "to":42}, {"from":26, "to":42}, {"from":27, "to":42}, {"from":42, "to":5}, {"from":42, "to":6}, {"from":9, "to":7}, {"from":6, "to":7}, {"from":44, "to":43}, {"from":7, "to":43}, {"from":28, "to":44}, {"from":30, "to":44}, {"from":31, "to":44}, {"from":29, "to":44}, {"from":44, "to":9}, {"from":12, "to":10}, {"from":5, "to":10}, {"from":46, "to":45}, {"from":10, "to":45}, {"from":37, "to":46}, {"from":38, "to":46}, {"from":32, "to":46}, {"from":33, "to":46}, {"from":34, "to":46}, {"from":35, "to":46}, {"from":36, "to":46}, {"from":46, "to":12}, {"from":9, "to":13}, {"from":12, "to":14}, {"from":14, "to":47}, {"from":13, "to":47}, {"from":39, "to":48}, {"from":41, "to":16}, {"from":16, "to":18}, {"from":16, "to":19}, {"from":16, "to":20}, {"from":16, "to":21}, {"from":16, "to":22}, {"from":16, "to":23}, {"from":18, "to":24}, {"from":19, "to":24}, {"from":20, "to":24}, {"from":16, "to":24}, {"from":18, "to":25}, {"from":19, "to":25}, {"from":20, "to":25}, {"from":16, "to":25}, {"from":18, "to":26}, {"from":19, "to":26}, {"from":20, "to":26}, {"from":16, "to":26}, {"from":21, "to":27}, {"from":22, "to":27}, {"from":23, "to":27}, {"from":18, "to":27}, {"from":19, "to":27}, {"from":20, "to":27}, {"from":16, "to":27}, {"from":43, "to":28}, {"from":28, "to":29}, {"from":29, "to":30}, {"from":29, "to":31}, {"from":45, "to":32}, {"from":45, "to":33}, {"from":45, "to":34}, {"from":33, "to":35}, {"from":32, "to":35}, {"from":34, "to":36}, {"from":33, "to":36}, {"from":32, "to":36}, {"from":35, "to":36}, {"from":36, "to":37}, {"from":36, "to":38}, {"from":47, "to":39}, {"from":52, "to":25}, {"from":52, "to":27}, {"from":52, "to":19}, {"from":52, "to":18}, {"from":52, "to":34}, {"from":52, "to":26}, {"from":36, "to":52}, {"from":29, "to":52}, {"from":52, "to":20}, {"from":52, "to":22}, {"from":52, "to":37}, {"from":52, "to":32}, {"from":52, "to":38}, {"from":52, "to":33}, {"from":52, "to":21}, {"from":52, "to":30}, {"from":52, "to":23}, {"from":52, "to":28}, {"from":52, "to":24}, {"from":52, "to":31}, {"from":52, "to":35}]};
var loopsJSON={"columns":["", "Pipelined", "II", "Speculated iterations", "Details"], "children":[{"name":"Component: add", "data":["", "", ""], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":134}]], "details":[{"type":"brief", "text":"Task function"}, {"type":"text", "text":"Task function"}, {"type":"text", "text":"Fmax bottlenck block: None"}, {"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual : Component", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html#ewa1462820640727"}]}], "children":[{"name":"add.B1.start", "data":["No", "n/a", "n/a"], "debug":[[{"filename":"Component invocation", "line":0}]], "details":[{"type":"brief", "text":"Divergent inner loop and..."}, {"type":"text", "text":"Loop not pipelined due to:", "details":[{"type":"text", "text":"Loop contains divergent inner loops. Making all inner loops unconditional should fix this problem. Not pipelining this loop will most likely lead to poor performance."}, {"type":"text", "text":"Loop iteration ordering: iterations of inner loop shown may get out of order with respect to the listed inner loop, as the number of iterations of the listed inner loop may be different for different iterations of this loop.", "details":[{"type":"text", "text":"add.B7 (%L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"170"}]}, {"type":"text", "text":"add.B4 (%L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"367"}]}]}]}, {"type":"text", "text":"Stallable instruction: n/a"}, {"type":"text", "text":"Maximum concurrent iterations: 1 due to not being pipelined"}, {"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual : Loops in Components", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html#ewa1462826976357"}]}], "children":[{"name":"add.B7", "data":["No", "n/a", "n/a"], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]], "details":[{"type":"brief", "text":"Unresolvable exit condition"}, {"type":"text", "text":"Loop not pipelined due to:", "details":[{"type":"text", "text":"Loop exit condition unresolvable at iteration initiation."}]}, {"type":"text", "text":"Stallable instruction: n/a"}, {"type":"text", "text":"Maximum concurrent iterations: 1 due to not being pipelined"}, {"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual : Loops in Components", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html#ewa1462826976357"}]}], "children":[{"name":"add.B8", "data":["Yes", "~103", "16"], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]], "details":[{"type":"brief", "text":"Memory dependency"}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"To: Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"To: Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"To: Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"172"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"To: Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"172"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"930"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1027"}]}, {"type":"text", "text":"To: Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"930"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1027"}]}, {"type":"text", "text":"To: Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}]}, {"type":"text", "text":"Most critical loop feedback path during scheduling:", "details":[{"type":"text", "text":"32.00 clock cycles Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"172"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}, {"type":"text", "text":"32.00 clock cycles Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"31.00 clock cycles Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"3.00 clock cycles 32-bit Floating-point Add Operation (%L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"174"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Select Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Integer Compare Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"930"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Select Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"930"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1027"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Select Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"172"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}, {"type":"text", "text":"1.00 clock cycle Select Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"0.30 clock cycles 1-bit And Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"917"}]}, {"type":"text", "text":"0.30 clock cycles 1-bit And Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"917"}]}]}, {"type":"text", "text":"II is an approximation due to the following stallable instructions:", "details":[{"type":"text", "text":"Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"930"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1027"}]}, {"type":"text", "text":"Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"930"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1027"}]}, {"type":"text", "text":"Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"Store Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"174"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"172"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}, {"type":"text", "text":"Load Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"172"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}]}, {"type":"text", "text":"Maximum concurrent iterations: Capacity of loop", "details":[{"type":"text", "text":"Use the %L viewer to estimate capacity", "links":[{"view":"Fmax II Report"}]}]}, {"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual : Loops in Components", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html#ewa1462826976357"}]}], "children":[]}]}, {"name":"add.B4", "data":["No", "n/a", "n/a"], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":367}]], "details":[{"type":"brief", "text":"Unresolvable exit condition"}, {"type":"text", "text":"Loop not pipelined due to:", "details":[{"type":"text", "text":"Loop exit condition unresolvable at iteration initiation."}]}, {"type":"text", "text":"Stallable instruction: n/a"}, {"type":"text", "text":"Maximum concurrent iterations: 1 due to not being pipelined"}, {"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual : Loops in Components", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html#ewa1462826976357"}]}], "children":[{"name":"add.B5", "data":["Yes", "~104", "16"], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]], "details":[{"type":"brief", "text":"Memory dependency"}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"To: Store Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Store Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"To: Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"369"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}]}, {"type":"text", "text":"Compiler failed to schedule this loop with smaller II due to memory dependency:", "details":[{"type":"text", "text":"From: Store Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"To: Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"369"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}]}, {"type":"text", "text":"Most critical loop feedback path during scheduling:", "details":[{"type":"text", "text":"32.00 clock cycles Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"32.00 clock cycles Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"369"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}, {"type":"text", "text":"31.00 clock cycles Store Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"3.00 clock cycles 32-bit Floating-point Add Operation (%L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"371"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Select Operation (%L > %L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"930"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1027"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Integer Compare Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"930"}]}, {"type":"text", "text":"1.00 clock cycle 32-bit Select Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"369"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}, {"type":"text", "text":"1.00 clock cycle Select Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"0.30 clock cycles 1-bit And Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"917"}]}, {"type":"text", "text":"0.30 clock cycles 1-bit And Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"917"}]}]}, {"type":"text", "text":"II is an approximation due to the following stallable instructions:", "details":[{"type":"text", "text":"Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"932"}]}, {"type":"text", "text":"Store Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"371"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"962"}]}, {"type":"text", "text":"Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"369"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}, {"type":"text", "text":"Load Operation (%L > %L > %L)", "links":[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"159"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert/tensorXL.cpp", "line":"369"}, {"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":"1037"}]}]}, {"type":"text", "text":"Maximum concurrent iterations: Capacity of loop", "details":[{"type":"text", "text":"Use the %L viewer to estimate capacity", "links":[{"view":"Fmax II Report"}]}]}, {"type":"text", "text":"See %L for more information", "links":[{"guide":"Reference Manual : Loops in Components", "link":"https://www.intel.com/content/www/us/en/programmable/documentation/ewa1462824960255.html#ewa1462826976357"}]}], "children":[]}]}]}]}]};
var loop_attrJSON={"name":"loop_attributes", "id":4294967295, "nodes":[{"name":"add", "id":1087708160, "clk":"No", "fmax":"240.00", "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":135}]], "type":"component", "children":[{"name":"add.B0.runOnce", "id":1087188544, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"1", "lt":"2.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}, {"name":"add.B1.start", "id":1087190080, "af":"240.00", "br":"1", "ci":"1", "fo":"Disabled", "ii":"n/a", "ll":"1", "lt":"66.000000", "mi":"n/a", "pl":"No", "tc":"0", "tn":"1", "details":[{"type":"text", "text":"Hyper-Optimized loop structure: n/a"}], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":135}]], "type":"loop", "children":[{"name":"add.B2", "id":1087190368, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"2", "lt":"0.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}, {"name":"add.B3", "id":1087191904, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"2", "lt":"0.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}, {"name":"add.B7", "id":1087191328, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"n/a", "ll":"2", "lt":"52.000000", "mi":"n/a", "pl":"No", "tc":"0", "tn":"1", "details":[{"type":"text", "text":"Hyper-Optimized loop structure: n/a"}], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":170}]], "type":"loop", "children":[{"name":"add.B8", "id":1087192480, "af":"240.00", "br":"1", "ci":"0", "fo":"Disabled", "ii":"103", "ll":"3", "lt":"156.000000", "mi":"1", "pl":"Yes", "tc":"0", "tn":"0", "details":[{"type":"text", "text":"Hyper-Optimized loop structure: n/a"}], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":172}]], "type":"loop"}]}, {"name":"add.B4", "id":1087192288, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"n/a", "ll":"2", "lt":"2.000000", "mi":"n/a", "pl":"No", "tc":"0", "tn":"1", "details":[{"type":"text", "text":"Hyper-Optimized loop structure: n/a"}], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":367}]], "type":"loop", "children":[{"name":"add.B5", "id":1087192192, "af":"240.00", "br":"1", "ci":"0", "fo":"Disabled", "ii":"104", "ll":"3", "lt":"109.000000", "mi":"1", "pl":"Yes", "tc":"0", "tn":"0", "details":[{"type":"text", "text":"Hyper-Optimized loop structure: n/a"}], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\tensorXL.cpp", "line":369}]], "type":"loop"}]}, {"name":"add.B9", "id":1087192768, "af":"240.00", "br":"1", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"2", "lt":"2.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}, {"name":"add.B6", "id":1087189312, "af":"240.00", "br":"1", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"2", "lt":"2.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}, {"name":"add.B11", "id":1087191136, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"2", "lt":"0.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}, {"name":"add.B10", "id":1087192096, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"2", "lt":"0.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}]}, {"name":"add.B12", "id":1087190752, "af":"240.00", "br":"0", "ci":"0", "fo":"Disabled", "ii":"1", "ll":"1", "lt":"2.000000", "mi":"n/a", "pl":"Yes", "tc":"0", "tn":"1", "type":"bb"}]}]};
var summaryJSON={"functionNameMapping":{"name":"Synthesized Function Name Mapping", "columns":["User-defined Function Name", "Mapped Function Name"], "children":[{"name":"public: static void __cdecl TensorXL::add(class TensorXL &, class TensorXL &, class TensorXL &)", "data":["add"], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\./tensorXL.h", "line":43}]]}]}, "estimatedResources":{"name":"Estimated Resource Usage", "columns":["Function Name", "ALUTs ", "FFs  ", "RAMs ", "DSPs ", "MLABs"], "children":[{"name":"add", "data":[18763, 22168, 28, 2, 170], "debug":[[{"filename":"C:\\Users\\hunto_efxy22i\\jupyterProjects\\HUBERT\\hubert\\./tensorXL.h", "line":43}]]}, {"name":"Total", "classes":["summary-highlight", "nohover"], "data":[18763, 22168, 28, 2, 170], "data_percent":[11.6787, 6.89904, 4.77002, 1.04167]}, {"name":"Available", "classes":["summary-highlight", "nohover"], "data":[160660, 321320, 587, 192, 0]}]}, "compileWarnings":{"name":"Compile Warnings", "children":[]}};
var warningsJSON={"nodes":[{"debug":[[{"filename":"quantact_testbench.cpp","line":"81"}]],"details":[{"text":"quantact_testbench.cpp:81:28: warning: expression result unused [-Wunused-value]"}],"name":"expression result unused [-Wunused-value]"},{"debug":[[{"filename":"tensor3dXL.cpp","line":"516"}]],"details":[{"text":"tensor3dXL.cpp:516:10: warning: reference to stack memory associated with local variable \'nullone\' returned [-Wreturn-stack-address]"}],"name":"reference to stack memory associated with local variable \'nullone\' returned [-Wreturn-stack-address]"}]};
var fileJSON=[{"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/hubertEnums.h", "name":"hubertEnums.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/hubertEnums.h", "content":"//hubert_enums.h, created by Hunter Messner for the HUBERT project\012\012#ifndef __HUBERT_ENUMS_H__\012#define __HUBERT_ENUMS_H__\012\012#include \"tensorXL.h\"\012#include \"tensor3dXL.h\"\012#include \"tensors.h\"\012#include \"tensor3d.h\"\012\012//enum to desribe all preloaded Tensors\012enum class QuantMode {none, symmetric};\012\012enum class ForceDequantMode{none, nonlinear, softmax, gelu, layernorm};\012\012struct scaled_tupleXL\012{//to get the most fidelity out of the translation, I make\012 //a struct that emulates the returned tuple of most forwards\012	TensorXL* matrix;\012	TensorXL* scaling_factor;\012};\012\012struct scaled_tuple3dXL\012{//same as scaled_tuple but 3d\012	Tensor3dXL* matrix;\012	TensorXL* scaling_factor;\012};\012\012struct scaled_tuple\012{//to get the most fidelity out of the translation, I make\012 //a struct that emulates the returned tuple of most forwards\012	Tensor* matrix;\012	TensorXL* scaling_factor;\012};\012\012struct scaled_tuple3d\012{//same as scaled_tuple but 3d\012	Tensor3d* matrix;\012	TensorXL* scaling_factor;\012};\012\012enum class preload\012{ //same name but with double underscore as word seperators instead of dots\012    activation_fn_approx__input_scaling_factor=0,\012    input_act__x_min,\012    input_act__x_max,\012    input_act__act_scaling_factor,\012    self_attn__k_proj__weight,\012    self_attn__k_proj__bias,\012    self_attn__k_proj__fc_scaling_factor,\012    self_attn__k_proj__weight_integer,\012    self_attn__k_proj__bias_integer,\012    self_attn__v_proj__weight,\012    self_attn__v_proj__bias,\012    self_attn__v_proj__fc_scaling_factor,\012    self_attn__v_proj__weight_integer,\012    self_attn__v_proj__bias_integer,\012    self_attn__q_proj__weight,\012    self_attn__q_proj__bias,\012    self_attn__q_proj__fc_scaling_factor,\012    self_attn__q_proj__weight_integer,\012    self_attn__q_proj__bias_integer,\012    self_attn__k_proj_act__x_min,\012    self_attn__k_proj_act__x_max,\012    self_attn__k_proj_act__act_scaling_factor,\012    self_attn__v_proj_act__x_min,\012    self_attn__v_proj_act__x_max,\012    self_attn__v_proj_act__act_scaling_factor,\012    self_attn__q_proj_act__x_min,\012    self_attn__q_proj_act__x_max,\012    self_attn__q_proj_act__act_scaling_factor,\012    self_attn__softmax__act__x_min,\012    self_attn__softmax__act__x_max,\012    self_attn__softmax__act__act_scaling_factor,\012    self_attn__attn_probs_act__x_min,\012    self_attn__attn_probs_act__x_max,\012    self_attn__attn_probs_act__act_scaling_factor,\012    self_attn__attn_act__x_min,\012    self_attn__attn_act__x_max,\012    self_attn__attn_act__act_scaling_factor,\012    self_attn__out_proj__weight,\012    self_attn__out_proj__bias,\012    self_attn__out_proj__fc_scaling_factor,\012    self_attn__out_proj__weight_integer,\012    self_attn__out_proj__bias_integer,\012    pre_self_attn_layer_norm_act__x_min,\012    pre_self_attn_layer_norm_act__x_max,\012    pre_self_attn_layer_norm_act__act_scaling_factor,\012    self_attn_layer_norm__weight,\012    self_attn_layer_norm__bias,\012    self_attn_layer_norm__shift,\012    self_attn_layer_norm__activation__x_min,\012    self_attn_layer_norm__activation__x_max,\012    self_attn_layer_norm__activation__act_scaling_factor,\012    fc1_act__x_min,\012    fc1_act__x_max,\012    fc1_act__act_scaling_factor,\012    fc2_act__x_min,\012    fc2_act__x_max,\012    fc2_act__act_scaling_factor,\012    fc1__weight,\012    fc1__bias,\012    fc1__fc_scaling_factor,\012    fc1__weight_integer,\012    fc1__bias_integer,\012    fc2__weight,\012    fc2__bias,\012    fc2__fc_scaling_factor,\012    fc2__weight_integer,\012    fc2__bias_integer,\012    pre_final_layer_norm_act__x_min,\012    pre_final_layer_norm_act__x_max,\012    pre_final_layer_norm_act__act_scaling_factor,\012    final_layer_norm__weight,\012    final_layer_norm__bias,\012    final_layer_norm__shift,\012    final_layer_norm__activation__x_min,\012    final_layer_norm__activation__x_max,\012    final_layer_norm__activation__act_scaling_factor\012};\012\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/loadTensors.cpp", "name":"loadTensors.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/loadTensors.cpp", "content":"//loadTensors.cpp, created by Hunter Messner for the HUBERT project\012\012#include <stdio.h>\012#include <cstring>\012#include <stdlib.h>\012#include \"tensorXL.h\"\012#include \"tensor3dXL.h\"\012#include \"tensors.h\"\012#include \"tensor3d.h\"\012#include \"loadTensors.h\"\012#include \"hubertEnums.h\"\012/*\012The file structure is as follows\012256 Chars that denote the Tensor name\0121 int for num rows, 1 int for num cols\012numrows*numcols floats following that.\012Then onto the next array\012*/\012\012//used in the testbench. Can use dynamic memory allocation\012TensorXL* loadTensorXL(preload idx)\012{\012    FILE* f;\012    fopen_s(&f, \"bin/MNLI_state.bin\", \"rb\"); //\012    FILE* l;\012    fopen_s(&l, \"bin/onelayer.txt\", \"r\"); //text file that includes names of indicies\012\012    char strname[256];\012    int el_requested = (int)idx;\012\012    int cur_el = 0;\012    while (fgets(strname, sizeof(strname), l)) { //we must read the file in order\012        if(strname[ strlen(strname) - 1 ] == '\\n')\012        {\012            strname[ strlen(strname) - 1 ] = \\0'; //get rid of newline\012        }\012        int str_len;\012        char str[256];\012        unsigned rows,cols;\012        float cur;\012        fread((void*)(&str_len), sizeof(str_len), 1, f);\012        fread((void*)(&str), str_len, 1, f);\012        str[str_len] = \\0'; //because I dont think its null terminated\012        if(strncmp(strname, str, 256) != 0)\012        { \012            printf(\"verification failed\");\012            exit(1); \012        }\012        fread((void*)(&rows), sizeof(rows), 1, f);\012        fread((void*)(&cols), sizeof(cols), 1, f);\012\012        //printf(\"%d %s (%d, %d)\\n\", str_len, str , rows, cols);\012        if(cur_el == el_requested)\012        {\012			TensorXL* localTensor = new TensorXL(rows, cols, 0.f);\012			int i;\012			for (i = 0; i < rows*cols; i++)\012			{\012				fread((void*)(&cur), sizeof(cur), 1, f);\012				int row = i / cols; // we are on this row at any given point\012				int col = i % cols;\012				TensorXL::set(*localTensor, row, col, cur);\012			}\012            return localTensor;\012        }\012        else\012        {\012			int i;\012			for (i = 0; i < rows*cols; i++)\012			{\012				fread((void*)(&cur), sizeof(cur), 1, f);\012			}\012            cur_el++;\012        }\012    }\012    fclose(f);\012    fclose(l);\012    return nullptr;\012	//this function allocates memory for the return value. delete outside the function\012}\012\012Tensor* loadTensor(preload idx)\012{\012	FILE* f;\012	fopen_s(&f, \"bin/MNLI_state.bin\", \"rb\"); //\012	FILE* l;\012	fopen_s(&l, \"bin/onelayer.txt\", \"r\"); //text file that includes names of indicies\012\012	char strname[256];\012	int el_requested = (int)idx;\012\012	int cur_el = 0;\012	while (fgets(strname, sizeof(strname), l)) { //we must read the file in order\012		if (strname[strlen(strname) - 1] == '\\n')\012		{\012			strname[strlen(strname) - 1] = \\0'; //get rid of newline\012		}\012		int str_len;\012		char str[256];\012		unsigned rows, cols;\012		float cur;\012		fread((void*)(&str_len), sizeof(str_len), 1, f);\012		fread((void*)(&str), str_len, 1, f);\012		str[str_len] = \\0'; //because I dont think its null terminated\012		if (strncmp(strname, str, 256) != 0)\012		{\012			printf(\"verification failed\");\012			exit(1);\012		}\012		fread((void*)(&rows), sizeof(rows), 1, f);\012		fread((void*)(&cols), sizeof(cols), 1, f);\012\012		if (cur_el == el_requested)\012		{\012			Tensor* localTensor = new Tensor(rows, cols, 0.f);\012			int i;\012			for (i = 0; i < rows*cols; i++)\012			{\012				fread((void*)(&cur), sizeof(cur), 1, f);\012				int row = i / cols; // we are on this row at any given point\012				int col = i % cols;\012				Tensor::set(*localTensor, row, col, cur);\012			}\012			return localTensor;\012		}\012		else\012		{\012			int i;\012			for (i = 0; i < rows*cols; i++)\012			{\012				fread((void*)(&cur), sizeof(cur), 1, f); //we have to read the data\012			} // but we cant assign it to anything or risk an out of bounds mem access\012			cur_el++;\012		}\012	}\012	fclose(f);\012	fclose(l);\012	return nullptr;\012}\012\012Tensor3dXL* loadGeneric3dXL(const char* fname)\012{\012	FILE* f;\012	fopen_s(&f, fname, \"rb\");\012	int str_len;\012	char str[256];\012	unsigned rows, cols, depth;\012	float cur;\012	fread((void*)(&str_len), sizeof(str_len), 1, f);\012	fread((void*)(&str), str_len, 1, f);\012	str[str_len] = \\0'; //because its not null terminated\012	fread((void*)(&depth), sizeof(depth), 1, f);\012	fread((void*)(&rows), sizeof(rows), 1, f);\012	fread((void*)(&cols), sizeof(cols), 1, f);\012\012	printf(\"%d %s (%d, %d, %d)\\n\", str_len, str, depth , rows, cols);\012\012	Tensor3dXL* localTensor = new Tensor3dXL();\012	Tensor3dXL::setRows(*localTensor, rows);\012	Tensor3dXL::setCols(*localTensor, cols);\012	int i;\012	for (int d = 0; d < depth; d++)\012	{\012		//allocate memory\012		TensorXL* oneLayer = new TensorXL(rows, cols, 0.f);\012		for (i = 0; i < rows*cols; i++)\012		{\012			fread((void*)(&cur), sizeof(cur), 1, f);\012			int row = i / cols; // we are on this row at any given point\012			int col = i % cols;\012			TensorXL::set(*oneLayer, row, col, cur);\012		}\012		Tensor3dXL::append(*localTensor, *oneLayer);\012	}\012\012	fclose(f);\012	return localTensor;\012}\012\012Tensor3d* loadGeneric3d(const char* fname)\012{\012	FILE* f;\012	fopen_s(&f, fname, \"rb\");\012	int str_len;\012	char str[256];\012	unsigned rows, cols, depth;\012	float cur;\012	fread((void*)(&str_len), sizeof(str_len), 1, f);\012	fread((void*)(&str), str_len, 1, f);\012	str[str_len] = \\0'; //because its not null terminated\012	fread((void*)(&depth), sizeof(depth), 1, f);\012	fread((void*)(&rows), sizeof(rows), 1, f);\012	fread((void*)(&cols), sizeof(cols), 1, f);\012\012	printf(\"%d %s (%d, %d, %d)\\n\", str_len, str, depth, rows, cols);\012\012	Tensor3d* localTensor = new Tensor3d();\012	Tensor3d::setRows(*localTensor, rows);\012	Tensor3d::setCols(*localTensor, cols);\012	int i;\012	for (int d = 0; d < depth; d++)\012	{\012		//allocate memory\012		Tensor* oneLayer = new Tensor(rows, cols, 0.f);\012		for (i = 0; i < rows*cols; i++)\012		{\012			fread((void*)(&cur), sizeof(cur), 1, f);\012			int row = i / cols; // we are on this row at any given point\012			int col = i % cols;\012			Tensor::set(*oneLayer, row, col, cur);\012		}\012		Tensor3d::append(*localTensor, *oneLayer);\012	}\012\012	fclose(f);\012	return localTensor;\012}\012\012TensorXL* loadGeneric2d(const char* fname)\012{\012	FILE* f;\012	fopen_s(&f, fname, \"rb\");\012	int str_len;\012	char str[256];\012	unsigned rows, cols;\012	float cur;\012	fread((void*)(&str_len), sizeof(str_len), 1, f);\012	fread((void*)(&str), str_len, 1, f);\012	str[str_len] = \\0'; //because its not null terminated\012	fread((void*)(&rows), sizeof(rows), 1, f);\012	fread((void*)(&cols), sizeof(cols), 1, f);\012\012	printf(\"%d %s (%d, %d)\\n\", str_len, str, rows, cols);\012\012	int i;\012	//allocate memory\012	TensorXL* tensor2d = new TensorXL(rows, cols, 0.f);\012	for (i = 0; i < rows*cols; i++)\012	{\012		fread((void*)(&cur), sizeof(cur), 1, f);\012		int row = i / cols; // we are on this row at any given point\012		int col = i % cols;\012		TensorXL::set(*tensor2d, row, col, cur);\012	}\012\012	fclose(f);\012	return tensor2d;\012}"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/loadTensors.h", "name":"loadTensors.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/loadTensors.h", "content":"//loadTensors.h, created by Hunter Messner for the HUBERT project\012#ifndef __HUBERT_LOADTENSOR_H__\012#define __HUBERT_LOADTENSOR_H__\012\012#include \"tensorXL.h\"\012#include \"tensor3dXL.h\"\012#include \"tensors.h\"\012#include \"tensor3d.h\"\012#include \"hubertEnums.h\"\012//currently only loads float tensors, easy customization to int\012TensorXL* loadTensorXL(preload);\012Tensor* loadTensor(preload);\012Tensor3dXL* loadGeneric3dXL(const char* fname);\012Tensor3d* loadGeneric3d(const char* fname);\012TensorXL* loadGeneric2d(const char* fname);\012\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/quantact_testbench.cpp", "name":"quantact_testbench.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/quantact_testbench.cpp", "content":"//quantact_testbench.cpp, created by Hunter Messner for the HUBERT project\012//actually a testbench for all of the modules\012#include \"HLS/hls.h\"\012#include \"HLS/stdio.h\"\012#include \"quantact_xl.h\"\012#include \"loadTensors.h\"\012#include \"hubertEnums.h\"\012#include \"tensors.h\" \012#include \"tensor3d.h\"\012#include \"tensorXL.h\"\012#include \"tensor3dXL.h\"\012//#include \"softmax.h\"\012//#include \"quantact.h\"\012//#include \"QuantLinear.h\"\012//#include \"IntLayerNorm.h\"\012//#include \"IntGELU.h\"\012//#include \"multiheadAttention.h\"\012//#include \"sentence_encoder_layer.h\"\012\012scaled_tuple3dXL QuantAct_forward_clone(\012	QuantAct_XL &self,\012	Tensor3dXL &x,\012	TensorXL &pre_act_scaling_factor,\012	Tensor3dXL &identity,\012	TensorXL &identity_scaling_factor,\012	TensorXL &specified_min,\012	TensorXL &specified_max);\012\012class exampleclass\012{\012public:\012	exampleclass(int init);\012	static void setme(exampleclass* inst, TensorXL &x_max, Tensor3dXL &x_min, int set);\012	int member_var;\012	QuantMode quant_mode;\012	//TensorXL x_min; //will throw errors\012};\012\012void exampleclass::setme(exampleclass* inst, TensorXL &x_max, Tensor3dXL &x_min, int set)\012{\012	inst->member_var = set;\012	TensorXL::set(x_max, 0, 0, 0.f);\012	Tensor3dXL::set(x_min, 0, 0, 0, 0.f);\012}\012\012exampleclass::exampleclass(int init)\012{\012	member_var = init;\012}\012\012void example_forward(exampleclass* inst)\012{\012	Tensor3dXL x_min;\012	TensorXL x_max;\012	exampleclass::setme(inst, x_max, x_min,10);\012}\012\012int main()\012{   \012	exampleclass* instance = new exampleclass(5);\012	int matrix[1][32];\012	matrix[0][0] = 5;\012	//example_forward(instance);\012	printf(\"%d\", instance->member_var);\012	scaled_tuple3dXL result1;\012	\012	\012	//QuantAct_XL verification\012	Tensor3dXL* matrix3d_testdata = loadGeneric3dXL(\"bin/quantact_layer0.bin\");\012	TensorXL* quantact_scaling_factor = loadGeneric2d(\"bin/quantact_sf_layer0.bin\");\012	QuantAct_XL testQuantAct(8, 0.95f, true, false, -1, QuantMode::symmetric);\012	QuantAct_XL::set_param(testQuantAct, preload::self_attn__q_proj_act__x_min,\012		preload::self_attn__q_proj_act__x_max,\012		preload::self_attn__q_proj_act__act_scaling_factor);\012	TensorXL nullb;\012	Tensor3dXL null3;\012	printf(\"lets go\\n\");\012	result1 = QuantAct_XL::QuantAct_forward(testQuantAct, *matrix3d_testdata, *quantact_scaling_factor, null3, nullb, nullb, nullb);\012	printf(\"lets go\\n\");\012	Tensor3dXL::print(*result1.matrix);\012	delete matrix3d_testdata, quantact_scaling_factor;\012\012	//QuantAct + softmax verification\012	/*\012	scaled_tuple3d softmax_result;\012	Tensor3d* matrix3d_testdata = loadGeneric3d(\"bin/softmax_layer0.bin\");\012	TensorXL* softmax_scaling_factor = new TensorXL(1,1, 0.0011662f);\012    Softmax testSoftmax (8, QuantMode::symmetric, ForceDequantMode::layernorm);\012	testSoftmax.set_param(preload::self_attn__softmax__act__x_min,\012		preload::self_attn__softmax__act__x_max,\012		preload::self_attn__softmax__act__act_scaling_factor);\012    softmax_result = testSoftmax.softmax_forward(matrix3d_testdata, softmax_scaling_factor);\012	delete matrix3d_testdata, softmax_scaling_factor;\012	*/\012	/*\012	 //QuantLinear verification\012	int thirtytwo = 32;\012	Tensor3dXL* matrix3d_testdata = loadGeneric3dXL(\"bin/quantlinear_layer0.bin\");\012	TensorXL* quantlinear_scaling_factor = new TensorXL(1, 1, 0.04931505f);\012	QuantLinear testQuantLinear(8, &thirtytwo, true, QuantMode::symmetric);\012	testQuantLinear.set_param(preload::self_attn__q_proj__fc_scaling_factor, \012		preload::self_attn__q_proj__weight, \012		preload::self_attn__q_proj__bias);\012	result1 = testQuantLinear.quantlinear_forward(matrix3d_testdata, quantlinear_scaling_factor);\012	*/\012	/*\012	//IntLayerNorm Verification\012	Tensor3dXL* matrix3d_testdata = loadGeneric3dXL(\"bin/intlayernorm_layer0.bin\");\012	TensorXL* intlayernorm_scaling_factor = new TensorXL(1, 1, 7.685552e-06f);\012	IntLayerNorm testIntLayerNorm(32, true, QuantMode::symmetric, ForceDequantMode::layernorm);\012	testIntLayerNorm.set_param(preload::self_attn_layer_norm__shift, preload::self_attn_layer_norm__weight, preload::self_attn_layer_norm__bias);\012	result1 = testIntLayerNorm.intlayernorm_forward(matrix3d_testdata, intlayernorm_scaling_factor);\012	printf(\"RESTULTS START\\n\");\012    Tensor3dXL::print(result1.matrix);\012    TensorXL::print(result1.scaling_factor);\012	*/\012	/*\012	//IntGELU Verification\012	Tensor3dXL* matrix3d_testdata = loadGeneric3dXL(\"bin/intgelu_layer0.bin\");\012	TensorXL* intgelu_scaling_factor = loadGeneric2d(\"bin/intgelu_sf_layer0.bin\");\012	IntGELU testintgelu(QuantMode::symmetric, ForceDequantMode::layernorm);\012	result1 = testintgelu.intgelu_forward(matrix3d_testdata, intgelu_scaling_factor);\012	printf(\"RESTULTS START\\n\");\012	Tensor3dXL::print(result1.matrix);\012	TensorXL::print(result1.scaling_factor);\012	*/\012	\012	/*\012	Tensor3dXL* q_testdata = loadGeneric3dXL(\"bin/q_multihead0.bin\");\012	Tensor3dXL* k_testdata = loadGeneric3dXL(\"bin/k_multihead0.bin\");\012	Tensor3dXL* v_testdata = loadGeneric3dXL(\"bin/v_multihead0.bin\");\012	TensorXL* q_scaling_factor = loadGeneric2d(\"bin/qsf_multihead0.bin\");\012	TensorXL* k_scaling_factor = loadGeneric2d(\"bin/vsf_multihead0.bin\");\012	TensorXL* v_scaling_factor = loadGeneric2d(\"bin/ksf_multihead0.bin\");\012	multiheadAttention testMULTIHEAD(768, 12, -1, -1, 0.1f, true, false, false, true, \012		false, 0, 8, QuantMode::symmetric, ForceDequantMode::layernorm, true);\012	result1 = testMULTIHEAD.multiheadAttention_forward(q_testdata, k_testdata, v_testdata, nullptr, nullptr, false, false, nullptr, false, false,\012		q_scaling_factor, k_scaling_factor, v_scaling_factor);\012	*/\012\012	/*\012	//SEL Verification\012	Tensor3dXL* matrix3d_testdata = loadGeneric3dXL(\"bin/tsel_input.bin\");\012	sentenceEncoderLayer testSEL(768, 3072, 12, 0.1f, 0.1f, 0.f, nullptr, false, 0.0f, 8, QuantMode::symmetric, ForceDequantMode::layernorm, false);\012	result1 = testSEL.sel_forward(matrix3d_testdata, nullptr);\012	printf(\"RESTULTS START\\n\");\012	Tensor3dXL::print(result1.matrix);\012	TensorXL::print(result1.scaling_factor);\012	*/\012\012}\012Tensor3dXL x_act1;\012TensorXL local_xmin2(1, 1, 0.f);\012TensorXL local_xmax2(1, 1, 0.f);\012Tensor3dXL temp3;\012Tensor3dXL temp25;\012scaled_tuple3dXL QuantAct_forward_clone(\012	QuantAct_XL &self,\012	Tensor3dXL &x,\012	TensorXL &pre_act_scaling_factor,\012	Tensor3dXL &identity,\012	TensorXL &identity_scaling_factor,\012	TensorXL &specified_min,\012	TensorXL &specified_max)\012{\012	x_act1 = Tensor3dXL();\012	Tensor3dXL::print(x);\012	Tensor3dXL::print(identity);\012	TensorXL::print(pre_act_scaling_factor);\012	TensorXL::print(identity_scaling_factor);\012	TensorXL::print(specified_min);\012	TensorXL::print(specified_max);\012	scaled_tuple3dXL b;\012	b.matrix = &x;\012	b.scaling_factor = &pre_act_scaling_factor;\012	return b;\012}"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/quantact_xl.cpp", "name":"quantact_xl.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/quantact_xl.cpp", "content":"//quantact_xl.cpp, created by Hunter Messner for the HUBERT project\012#include \"HLS/hls.h\"\012#include \"HLS/stdio.h\"\012#include \"tensorXL.h\" \012#include \"tensor3dXL.h\" \012#include \"quantact_xl.h\"\012#include \"loadTensors.h\"\012#include \"hubertEnums.h\"\012#include <iostream>\012\012typedef Tensor3dXL T3d;\012typedef TensorXL T2d;\012typedef scaled_tuple3dXL tuple;\012\012TensorXL x_min_xl;//This is only ever of size one during inference at least\012TensorXL x_max_xl;\012TensorXL act_scaling_factor_xl;\012\012QuantAct_XL::QuantAct_XL(\012	int activation_bit_i, \012    float act_range_momentum_i,\012    bool running_stat_i,\012    bool per_channel_i,\012    int channel_len,\012    QuantMode quant_mode_i)\012{\012    activation_bit = activation_bit_i;\012    act_range_momentum= act_range_momentum_i;\012    running_stat = running_stat_i;\012    quant_mode = quant_mode_i;\012    per_channel = per_channel_i;\012\012    if(per_channel)\012    {\012		//assert(channel_len > 0);\012		x_min_xl = T2d(1, channel_len, 0.0f);\012		x_max_xl = T2d(1, channel_len, 0.0f);\012		act_scaling_factor_xl = T2d(1, channel_len, 0.0f);\012\012    }\012	//loading xmin and xmax is done by the set param function\012}\012\012QuantAct_XL::~QuantAct_XL()\012{\012	//delete x_min;\012	//delete x_max;\012	//delete act_scaling_factor;\012}\012\012T3d x_act;\012T2d local_xmin(1, 1, 0.f);\012T2d local_xmax(1, 1, 0.f);\012T3d temp;\012T3d temp2;\012\012tuple QuantAct_XL::QuantAct_forward(\012	QuantAct_XL &self,\012	T3d &x, \012	T2d &pre_act_scaling_factor,\012	T3d &identity,\012	T2d &identity_scaling_factor,\012	T2d &specified_min,\012	T2d &specified_max,\012	bool testing)\012{\012	 printf(\"lets go 2\\n\");\012	//identity and x are 22x1x768 or 12x22x22.\012	//pre_act_scaling factor is 1x768\012	//identity scaling factor is 1x1\012	//x_act = T3d(x);\012	printf(\"lets go 3\\n\");\012    if(identity.null)\012    {\012        x_act = x;\012    }\012    else\012    {\012        T3d::add(x, identity, x_act);\012    }\012	printf(\"lets go 4\\n\");\012	//T2d local_xmin(1, 1, 0.f);\012	//T2d local_xmax(1, 1, 0.f);\012\012	if (self.running_stat)\012	{\012		if (!self.per_channel)\012		{\012			temp = T3d(x_act);\012			T3d::min(temp, temp);\012			T3d::toTwoD(temp, local_xmin);\012\012			temp2 = T3d(x_act);\012			T3d::max(temp2, temp2);\012			T3d::toTwoD(temp2, local_xmax);\012		}\012		else\012		{\012			//assert(false);\012		}\012\012		//Initialization \012		if (T2d::eq(x_min_xl, x_max_xl))\012		{\012			T2d::add(x_min_xl, local_xmin, x_min_xl);\012			T2d::add(x_max_xl, local_xmax, x_max_xl);\012		}\012		else if (self.act_range_momentum == -1)\012		{\012			float obj_min = T2d::one(x_min_xl);\012			float obj_max = T2d::one(x_max_xl);\012			float localmin = T2d::one(local_xmin);\012			float localmax = T2d::one(local_xmax);\012\012			if (localmax > obj_max)\012			{\012				T2d::set(x_max_xl, 0, 0, localmax);\012			}\012			if (localmin < obj_min)\012			{\012				T2d::set(x_min_xl, 0, 0, localmin);\012			}\012		}\012		else\012		{\012			//here I am assuming xmin and xmax are 1x1\012			float objmin = T2d::one(x_min_xl);\012			float localmin = T2d::one(local_xmin);\012			T2d::set(x_min_xl, 0, 0, objmin*self.act_range_momentum + localmin * (1 - self.act_range_momentum));\012\012			float objmax = T2d::one(x_max_xl);\012			float localmax = T2d::one(local_xmax);\012			T2d::set(x_max_xl, 0, 0, objmax*self.act_range_momentum + localmax * (1 - self.act_range_momentum));\012		}\012	}\012\012    if(self.quant_mode == QuantMode::none)\012    {\012        tuple returnme;\012        returnme.matrix = &x_act;\012        returnme.scaling_factor=nullptr; \012        return returnme;\012    }\012\012    if(!specified_min.null) \012		x_min_xl = specified_min;\012    if(!specified_max.null) \012		x_min_xl = specified_max;\012\012	act_scaling_factor_xl = *QuantAct_XL::symmetric_linear_quantization_params(self.activation_bit, x_min_xl, x_max_xl, self.per_channel);\012    \012	if (testing)\012	{\012		//TensorXL* actsf_v = loadGeneric2d(\"bin/actsf_verification.bin\");\012		//TensorXL::eq_verbose(actsf_v, act_scaling_factor);\012	}\012\012    T3d* quant_act_int = nullptr;\012    if(pre_act_scaling_factor.null)\012    {\012        quant_act_int = QuantAct_XL::symmetric_quant_forward(x, self.activation_bit, act_scaling_factor_xl);\012    }\012    else\012    {\012        quant_act_int = fixedpoint_mul(x, pre_act_scaling_factor, self.activation_bit, self.quant_mode, act_scaling_factor_xl, identity, identity_scaling_factor);\012    }\012\012	if (testing)\012	{\012		//Tensor3dXL* qai_v = loadGeneric3dXL(\"bin/qai_verification.bin\");\012		//Tensor3dXL::eq(qai_v, quant_act_int);\012	}\012\012    T2d correct_output_scale(act_scaling_factor_xl);\012	//correct output scale has just one element while quant act int has 2\012    T3d::mul_scalar(*quant_act_int, T2d::one(correct_output_scale), *quant_act_int);\012    tuple returnme;\012	if (testing)\012	{\012		//Tensor3dXL* qai_v = loadGeneric3dXL(\"bin/out_verification.bin\");\012		//Tensor3dXL::eq(qai_v, quant_act_int);\012	}\012    returnme.matrix = quant_act_int;\012    returnme.scaling_factor = &act_scaling_factor_xl; //global variables persist outside this function\012    return returnme;\012}\012\012T2d scale_xl;\012T2d* QuantAct_XL::symmetric_linear_quantization_params(unsigned num_bits,\012                                        T2d& saturation_min,\012                                        T2d& saturation_max,\012                                        bool per_channel)\012{\012    /*\012    Compute the scaling factor with the given quantization range for symmetric quantization.\012\012    Parameters:\012    ----------\012    saturation_min: lower bound for quantization range\012    saturation_max: upper bound for quantization range\012    \012    */\012\012    scale_xl = T2d(saturation_min);\012    unsigned n =  (unsigned int)exp2( num_bits - 1 ) - 1;\012    if (per_channel)\012    { // saturation min and max are Rows\012		for (unsigned i = 0; i < T2d::getCols(saturation_min); i++)\012		{//custom max loop\012			float x = fabs(T2d::get(saturation_min, 0, i)); \012			float y = fabs(T2d::get(saturation_max, 0, i));\012			if (x > y)\012			{\012				T2d::set(scale_xl, 0, i, x);\012			}\012			else\012			{\012				T2d::set(scale_xl, 0, i, y);\012			}\012		}\012		T2d::clamp(scale_xl, 1e-8f, FLT_MAX, scale_xl);\012		T2d::div_scalar(scale_xl, (float)n, scale_xl);\012    }\012    else\012    {//saturation min and max are one element tensors\012        T2d::set(scale_xl,0,0, fmax(fabs(T2d::one(saturation_min)), fabs((T2d::one(saturation_max)))));\012        T2d::clamp(scale_xl, 1e-8f, FLT_MAX, scale_xl);\012        T2d::div_scalar(scale_xl, (float)n, scale_xl);\012    }\012    return &scale_xl;\012}\012\012\012T2d zero_point;\012T3d* QuantAct_XL::symmetric_quant_forward(T3d &x, int k, T2d& specified_scale)\012{\012    T2d* scale = nullptr;\012    if(!specified_scale.null)\012    {\012        scale = &specified_scale;\012    }\012	zero_point = T2d(1,1,0.f);\012\012    float n = exp2f(float(k - 1)) - 1;\012\012    T3d* new_quant_x = QuantAct_XL::linear_quantize(x, *scale, zero_point);\012    T3d::clamp(*new_quant_x, -n, n-1, *new_quant_x);\012    return new_quant_x;\012}\012\012T3d x_xl;\012T2d scaleXL;\012T3d* QuantAct_XL::linear_quantize(T3d &x_c, T2d &scale_c, T2d &zero_point)\012{\012    //scale is 1 when x is truely 3d. When x is 2d, scale is also 2d (or at least broadcastable.)\012	scaleXL = T2d(scale_c);\012	x_xl = T3d(x_c);\012	T2d::reciprocal(scaleXL, scaleXL);\012	if (T3d::getDepth(x_xl) != 1)\012	{\012		T3d::mul_scalar(x_xl, T2d::one(scaleXL), x_xl);\012	}\012	else\012	{\012		T3d::mul_dot(x_xl, scaleXL, x_xl);\012	}\012    T3d::add_scalar(x_xl, T2d::one(zero_point), x_xl);\012    T3d::roundTensor(x_xl, x_xl);\012	\012    return &x_xl;\012}\012\012T3d output_xl;\012T2d space(1, 1, 0.f);\012T3d z_int;\012T2d _A;\012T2d _B;\012T2d new_scale;\012T2d m, e, twos;\012T3d wx_int;\012T2d m1, e1;\012T3d output1;\012T3d* QuantAct_XL::fixedpoint_mul(\012        T3d &pre_act,\012        T2d &pre_act_scaling_factor,\012        int bit_num,\012        QuantMode quant_mode,\012        T2d &z_scaling_factor,\012        T3d &identity,\012        T2d &identity_scaling_factor\012    )\012{\012    float n ;\012    if (quant_mode == QuantMode::symmetric)\012    {\012        n = (float)exp2(bit_num - 1) -1;\012    }\012    else{\012        n = (float)exp2(bit_num) - 1;\012    }\012    \012    z_int = T3d(pre_act);\012    T3d::div_dot(pre_act, pre_act_scaling_factor, z_int); \012    T3d::roundTensor(z_int, z_int);\012\012    //the following is in double precision in the code, but I did not make it double precision here\012    _A = T2d(pre_act_scaling_factor);\012    _B = T2d(z_scaling_factor);\012    new_scale = T2d(_A);\012    T2d::div_dot(_A, _B, new_scale);\012    \012    m = T2d(new_scale);\012    e = T2d(new_scale);\012    T2d::tensor_frexp(new_scale, m, e);\012    output_xl = T3d(z_int);\012	\012	twos = T2d(T3d::getRows(output_xl), T3d::getCols(output_xl), 2.0f);\012	T2d::pow_dot(twos, e, twos); //use twos as temp storage\012	T3d::div_dot(output_xl, twos, output_xl);\012    T3d::mul_dot(output_xl, m, output_xl);\012    T3d::roundTensor(output_xl, output_xl);\012\012    if(!identity.null)\012    {\012        wx_int = T3d(identity);\012        T3d::div_dot(identity, identity_scaling_factor, identity);\012        T3d::roundTensor(identity, wx_int);\012\012        _A = T2d(identity_scaling_factor);\012        _B = T2d(z_scaling_factor);\012        new_scale = T2d(_A);\012        T2d::div_dot(_A, _B, new_scale);\012        m1 = T2d(new_scale);\012        e1 = T2d(new_scale);\012        T2d::tensor_frexp(new_scale, m1, e1);\012\012        output1 = T3d(wx_int);\012        T3d::mul_dot(wx_int, m1, output1);\012		twos = T2d(T3d::getRows(output1), T3d::getCols(output1), 2.0f);\012        T2d::pow_dot(twos, e1, e1); //use e1 as temp storage\012        T3d::div_dot(output1, e1, output1);\012        T3d::roundTensor(output1, output1);\012        T3d::add(output_xl, output1, output_xl);\012    }\012\012    if( bit_num == 4 || bit_num == 8 || bit_num == 16)\012    {\012        if(quant_mode == QuantMode::symmetric)\012        {\012            T3d::clamp(output_xl, -n-1, n, output_xl);\012            return &output_xl;\012        }\012        else{\012            T3d::clamp(output_xl, 0, n, output_xl);\012            return &output_xl;\012        }\012    }\012    else{\012        return &output_xl;\012    }\012}\012\012\012void QuantAct_XL::set_param(QuantAct_XL &self, preload x_min_n, preload x_max_n, preload act_scaling_factor_n)\012{\012	x_min_xl = *loadTensorXL(x_min_n);\012	x_max_xl = *loadTensorXL(x_max_n);\012	act_scaling_factor_xl = *loadTensorXL(act_scaling_factor_n);\012}\012\012"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/quantact_xl.h", "name":"quantact_xl.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/quantact_xl.h", "content":"//quantact_xl.h, created by Hunter Messner for the HUBERT project\012#ifndef __HUBERT_QUANTACT_XL_H__\012#define __HUBERT_QUANTACT_XL_H__\012\012#include \"HLS/hls.h\"\012#include \"HLS/stdio.h\"\012#include \"tensorXL.h\"\012#include \"tensor3dXL.h\"\012#include <iostream>\012#include \"hubertEnums.h\"\012//no typedefs in headers\012class QuantAct_XL\012{\012    public:\012    //initializer\012    QuantAct_XL(\012		int activation_bit, \012		float act_range_momentum=0.95f,\012		bool running_stat=true,\012		bool per_channel=false,\012		int channel_len= -1,\012		QuantMode quant_mode = QuantMode::none);\012\012	~QuantAct_XL();\012\012    //other functions\012	static scaled_tuple3dXL QuantAct_forward(\012		QuantAct_XL &self,\012		Tensor3dXL &x,\012        TensorXL &pre_act_scaling_factor,\012        Tensor3dXL &identity,\012        TensorXL &identity_scaling_factor,\012        TensorXL &specified_min,\012        TensorXL &specified_max,\012		bool testing = false);\012\012    static TensorXL* symmetric_linear_quantization_params(\012		unsigned num_bits,\012        TensorXL &saturation_min,\012        TensorXL &saturation_max,\012        bool per_channel=false);\012\012    static Tensor3dXL* symmetric_quant_forward(Tensor3dXL &x, int k, TensorXL &specified_scale);\012    static Tensor3dXL* linear_quantize(Tensor3dXL &x, TensorXL &scale, TensorXL &zero_point);\012    static Tensor3dXL* fixedpoint_mul(\012        Tensor3dXL &pre_act,\012        TensorXL &pre_act_scaling_factor,\012        int bit_num,\012        QuantMode quant_mode,\012        TensorXL &z_scaling_factor,\012        Tensor3dXL &identity,\012        TensorXL &identity_scaling_factor\012    );\012	static void set_param(QuantAct_XL &self, preload x_min_n, preload x_max_n, preload act_scaling_factor_n);\012\012    //members\012    int activation_bit;\012    float act_range_momentum;\012    bool running_stat;\012    QuantMode quant_mode;\012    bool per_channel;\012};\012\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3d.cpp", "name":"tensor3d.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3d.cpp", "content":"//tensor3d.cpp\012// 3d HLS tensor implementation for the HUBERT project.\012//created by Hunter Messner on 7/19/2021\012\012#include \"HLS/hls.h\"\012#include \"HLS/math.h\"\012#include \"HLS/stdio.h\"\012#include \"tensors.h\"\012#include \"tensor3d.h\"\012#include \"tensor3dXL.h\"\012#include <iostream>\012\012/*                    DEFINITIONS                      */\012\012Tensor3d::Tensor3d(Tensor3d *A) //Takes 2d matrixes from the pointer and creates new Tensors based on them\012{\012	t_numCols = getCols(*A); \012	t_numRows = getRows(*A);\012	t_depth = getDepth(*A);\012	for (unsigned d = 0; d < t_depth; d++)\012	{\012		matrix[d] = Tensor(get(*A, d));//TODO: almost certainly wrong. Dont care right now\012	}\012	null = false;\012}\012\012\012Tensor3d::Tensor3d(Tensor *A) //Takes a 2d matrix and copies it into the first layer.\012{\012	t_numCols = Tensor::getCols(*A);\012	t_numRows = Tensor::getRows(*A);\012	t_depth = 1;\012	matrix[0] = A;\012	null = false;\012}\012\012\012Tensor3d::Tensor3d(int dep, int row, int col, float init)\012{\012	t_numCols = col;\012	t_numRows = row;\012	t_depth = dep;\012	for (unsigned d = 0; d < dep; d++)\012	{\012		matrix[d] = Tensor(row, col, init);;//TODO: almost certainly wrong. Dont care right now \012	}\012	null = false;\012}\012\012\012Tensor3d::Tensor3d(void)\012{ //if using this in conjuction with append(), make sure to setCols and setRows\012	t_numCols = 0;\012	t_numRows = 0;\012	t_depth = 0;\012	null = true;\012}\012\012\012Tensor3d::~Tensor3d()\012{\012	/*\012	for (unsigned d = 0; d < t_depth; d++)\012	{\012		if (nullptr != matrix[d]) { delete matrix[d]; }\012	}\012	*/\012	null = true;\012}\012\012//special multiply\012 void Tensor3d::linear_mul(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	Tensor::transpose(B);\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::mul_cross(get(A, d), B, get(C, d));\012	}\012	setCols(C, Tensor::getCols(B));\012	setRows(C, getRows(A));\012	Tensor::transpose(B);\012}\012\012 void Tensor3d::bmm(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{ //for when they both have the same size. \012	//We assume B is the same shape as A but compatible to multiply \012	//assuming a 22x64 * 22x64 but we transpose the second input\012	//assert(getCols(A) == getCols(B));\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor rhs = get(B, d);\012		Tensor::transpose(rhs);\012		Tensor::mul_cross(get(A, d), rhs, get(C, d));\012		Tensor::transpose(rhs);\012	}\012	setCols(C, getRows(B)); //rows is correct because its un-transposed\012	setRows(C, getRows(A));\012}\012\012 void Tensor3d::bmm2(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{ //for when they both have the same size. \012	//We assume B is already \"transposed\". Also assuming a 22x22 * 22x64\012	//assert(getCols(A) == getRows(B));\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::mul_cross_secondary(get(A, d), get(B, d), get(C, d));\012	}\012	setCols(C, getCols(B));\012	setRows(C, getRows(A));\012}\012\012//2d broadcasting across 3d\012 void Tensor3d::add(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	//defer error checking to a layer by layer basis. \012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::add(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3d::sub(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::sub(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3d::mul_dot(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::mul_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3d::div_dot(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::div_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3d::pow_dot(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::pow_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3d::add(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::add(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3d::sub(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::sub(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3d::mul_dot(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::mul_dot(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3d::div_dot(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::div_dot(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3d::pow_dot(Tensor3d &A, Tensor3d &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::pow_dot(get(A, d), get(B, d), get(C, d));\012	}\012}\012\012//scalar type\012 void Tensor3d::add_scalar(Tensor3d &A, float B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::add_scalar(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3d::mul_scalar(Tensor3d &A, float B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::mul_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3d::sub_scalar(Tensor3d &A, float B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::sub_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3d::sub_scalar(float B, Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::sub_scalar(B, get(A, d), get(C, d));\012	}\012}\012 void Tensor3d::div_scalar(Tensor3d &A, float B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::div_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3d::pow_scalar(Tensor3d &A, float B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::pow_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3d::max(Tensor3d &A, int dim, Tensor3d &C)\012{\012	if (dim == 0 || dim == 1)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			Tensor::max(get(A, d), dim, get(C, d));\012		}\012		setCols(C, Tensor::getCols(get(C, 0))); // the rows and cols of the layers were updated\012		setRows(C, Tensor::getRows(get(C, 0))); // but we still need to update the 3d matrix's\012	}\012	else //dim ==2\012	{\012		unsigned i, j;\012		float largest;\012		bool first = true;\012		for (i = 0; i < A.t_numCols; i++)\012		{\012			for (j = 0; j < A.t_numRows; j++)\012			{\012				for (unsigned d = 0; d < A.t_depth; d++)\012				{\012					if (first)\012					{\012						largest = Tensor3d::get(A, i, j, d);\012						first = false;\012					}\012					else {\012						if (largest < Tensor3d::get(A, j, i, d))\012						{\012							largest = Tensor3d::get(A, j, i, d);\012						}\012					}\012				}\012				Tensor3d::set(C, i, j, 0, largest);\012				first = true;\012			}\012		}\012		//i know the dimentions of C, so i set them for safety\012		setDepth(C, 1);\012		setCols(C, A.t_numCols);\012		setRows(C, A.t_numRows);\012	}\012}\012 void Tensor3d::min(Tensor3d &A, int dim, Tensor3d &C)\012{\012	if (dim == 0 || dim == 1)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			Tensor::min(get(A, d), dim, get(C, d));\012		}\012		setCols(C, Tensor::getCols(get(C, 0))); // the rows and cols of the layers were updated\012		setRows(C, Tensor::getRows(get(C, 0))); // but we still need to update the 3d matrix's\012	}\012	else //dim ==2\012	{\012		unsigned i, j;\012		float smallest;\012		bool first = true;\012		for (i = 0; i < A.t_numCols; i++)\012		{\012			for (j = 0; j < A.t_numRows; j++)\012			{\012				for (unsigned d = 0; d < A.t_depth; d++)\012				{\012					if (first)\012					{\012						smallest = Tensor3d::get(A, i, j, d);\012						first = false;\012					}\012					else {\012						if (smallest > Tensor3d::get(A, j, i, d))\012						{\012							smallest = Tensor3d::get(A, j, i, d);\012						}\012					}\012				}\012				Tensor3d::set(C, i, j, 0, smallest);\012				first = true;\012			}\012		}\012		//i know the dimentions of C, so i set them for safety\012		setDepth(C, 1);\012		setCols(C, A.t_numCols);\012		setRows(C, A.t_numRows);\012	}\012}\012\012 void Tensor3d::max(Tensor3d &A, Tensor3d &C) // full collapse\012{\012	Tensor3d::max(A, 0, A);\012	Tensor3d::max(A, 1, A);\012	Tensor3d::max(A, 2, A);\012}\012\012 void Tensor3d::min(Tensor3d &A, Tensor3d &C)\012{\012	Tensor3d::min(A, 0, A);\012	Tensor3d::min(A, 1, A);\012	Tensor3d::min(A, 2, A);\012}\012\012 void Tensor3d::max_scalar(Tensor3d &A, float compare, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::max_scalar(get(A, d), compare, get(C, d));\012	}\012}\012\012 void Tensor3d::min_scalar(Tensor3d &A, float compare, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::min_scalar(get(A, d), compare, get(C, d));\012	}\012}\012\012 void Tensor3d::min_dot(Tensor3d &A, Tensor &B, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::min_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3d::abs_tensor(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::abs_tensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3d::floor_tensor(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::floor_tensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3d::exp2_tensor(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::exp2_tensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3d::clamp(Tensor3d &A, float min, float max, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::clamp(get(A, d), min, max, get(C, d));\012	}\012}\012\012 void Tensor3d::roundTensor(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::roundTensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3d::reciprocal(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::reciprocal(get(A, d), get(C, d));\012	}\012}\012 void Tensor3d::sum(Tensor3d &A, int dim, Tensor3d &C)\012{\012	if (dim == 0 || dim == 1)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			Tensor::sum(get(A, d), dim, get(C, d));\012		}\012		setCols(C, Tensor::getCols(get(C, 0))); // the rows and cols of the layers were updated\012		setRows(C, Tensor::getRows(get(C, 0))); // but we still need to update the 3d matrix's\012	}\012\012	else\012	{\012		float running;\012		running = float(0);\012		for (unsigned i = 0; i < A.t_numCols; i++)\012		{\012			for (unsigned j = 0; j < A.t_numRows; j++)\012			{\012				for (unsigned d = 0; d < A.t_depth; d++)\012				{\012					running += get(A, j, i, d);\012				}\012				set(C, i, j, 0, running);\012				running = 0;\012			}\012		}\012		setDepth(C, 1);\012		setCols(C, A.t_numCols);\012		setRows(C, A.t_numRows);\012	}\012}\012\012 void Tensor3d::sign(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::sign(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3d::mean(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::mean(get(A, d), get(C, d));\012		setRows(C, Tensor::getRows(get(C, d))); //propogate the row change up to the 3d level\012		setCols(C, Tensor::getCols(get(C, d))); // and col change\012	}\012}\012\012 void Tensor3d::sqrt_tensor(Tensor3d &A, Tensor3d &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::sqrt_tensor(get(A, d), get(C, d));\012	}\012}\012\012//adressing methods where dep is depth and select the 2d array you want.\012 float Tensor3d::get(Tensor3d &tensor, const unsigned &row, const unsigned &col, const unsigned &dep)\012{\012	if (dep < getDepth(tensor))\012	{\012		return Tensor::get(tensor.matrix[dep], row, col);\012	}\012	else\012	{\012		//assert(false);\012		return 0;\012	}\012}\012\012 void Tensor3d::set(Tensor3d &tensor, const unsigned &row, const unsigned &col, const unsigned &dep, float val)\012{\012	if (dep < getDepth(tensor))\012	{\012		Tensor::set(tensor.matrix[dep], row, col, val);\012	}\012}\012\012 Tensor& Tensor3d::get(Tensor3d &tensor, const unsigned &dep)\012{\012	if (dep < getDepth(tensor))\012	{\012		return tensor.matrix[dep];\012	}\012	else\012	{\012		//assert(false);\012		static Tensor nullone;\012		return nullone;\012	}\012}\012 void Tensor3d::set(Tensor3d &tensor, const unsigned &dep, Tensor &slice)\012{//does a copy operation from slice to tensor\012	if (dep < getDepth(tensor))\012	{\012		if (!slice.null)\012		{\012			tensor.matrix[dep] = &slice; //does NOT COPY. simply points to already existing tensor\012		}\012		else\012		{\012			tensor.matrix[dep] = nullptr;\012		}\012	}\012}\012\012 Tensor* Tensor3d::twoD(Tensor3d &A) //analog to one for 2d Tensors, but checks for ONE layer \012{\012	if (getDepth(A) == 1)\012	{\012		return &get(A,0);\012	}\012	else\012	{\012		//printf(\"faulty assumption\");\012		//assert(false);\012		return nullptr;\012	}\012}\012\012 void Tensor3d::toTwoD(Tensor3d &A, Tensor &C)\012{\012	if (getDepth(A) == 1)\012	{\012		Tensor::copy(*twoD(A), C);\012	}\012	else if (getRows(A) == 1)\012	{// Here we transform depth into rows. depth 0 being the first row\012		Tensor::setRows(C, getDepth(A));\012		Tensor::setCols(C, getCols(A));\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			for (unsigned c = 0; c < getCols(A); c++)\012			{\012				Tensor::set(C, d, c, get(A, 0, c, d));\012			}\012		}\012	}\012	else if (getCols(A) == 1)\012	{// Here we transform depth into cols. depth 0 being the first column\012		Tensor::setCols(C, getDepth(A));\012		Tensor::setRows(C, getRows(A));\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			for (unsigned r = 0; r < getRows(A); r++)\012			{\012				Tensor::set(C, r, d, get(A, r, 0, d));\012			}\012		}\012	}\012	else\012	{\012		printf(\"array cannot be reduced\\n\");\012		//assert(false);\012	}\012}\012\012 void Tensor3d::append(Tensor3d &tensor, Tensor &slice)\012{\012	setDepth(tensor, getDepth(tensor)+1);\012	set(tensor, getDepth(tensor)-1 , slice);\012}\012\012//helper functions\012  void  Tensor3d::print(Tensor3d &A)\012{\012	printf(\"Tensor3d\\n[\");\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::print(get(A,d));\012		printf(\",\\n\");\012	}\012	printf(\"] End Tensor3d\\n\");\012}\012\012  void  Tensor3d::print_brief(Tensor3d &A)\012{\012	printf(\"Tensor3d\\n[\");\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		Tensor::print_brief(get(A, d));\012		printf(\",\\n\");\012	}\012	printf(\"] End Tensor3d\\n\");\012}\012\012 inline unsigned Tensor3d::getRows(Tensor3d &a)\012{\012	return a.t_numRows;\012}\012\012 inline unsigned Tensor3d::getCols(Tensor3d &a)\012{\012	return a.t_numCols;\012}\012\012 inline unsigned Tensor3d::getDepth(Tensor3d &a)\012{\012	return a.t_depth;\012}\012\012 bool Tensor3d::eq(Tensor3d &A, Tensor3d &B)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		if (!Tensor::eq_verbose(get(A,d), get(B,d)))\012		{\012			return false;\012		}\012	}\012	return true;\012}\012\012//private helper functions\012 void Tensor3d::setRows(Tensor3d &a, int num)\012{\012	a.t_numRows = num;\012}\012\012 void Tensor3d::setCols(Tensor3d &a, int num) \012{\012	a.t_numCols = num;\012}\012\012 void Tensor3d::setDepth(Tensor3d &a, int num)\012{\012	a.t_depth = num;\012}\012\012 bool Tensor3d::sameSize(Tensor3d &A, Tensor &B)\012{\012	return Tensor3d::getRows(A) == Tensor::getRows(B) && Tensor3d::getCols(A) == Tensor::getCols(B);\012}\012\012 bool Tensor3d::sameSize(Tensor3d &A, Tensor3d &B) \012{\012	return getRows(A) == getRows(B) && \012		getCols(A) == getCols(B) && \012		getDepth(A) == getDepth(B);\012}\012\012 bool Tensor3d::sameDep(Tensor3d &A, Tensor3d &B)\012{\012	return getDepth(A) == getDepth(B);\012}\012"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3d.h", "name":"tensor3d.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3d.h", "content":"//tensor3d.h\012// 3d HLS tensor implementation for the HUBERT project.\012//created by Hunter Messner on 7/19/2021\012\012\012#ifndef __HUBERT_TENSOR3D_H__\012#define __HUBERT_TENSOR3D_H__\012\012#include \"tensors.h\"\012#include \"tensor3dXL.h\"\012\012/*                TUNING AND OPTIONS                   */\012const unsigned MAX_DEPTH = 22;\012\012class Tensor3d{\012    public:\012        unsigned int t_numRows;\012        unsigned int t_numCols;\012		unsigned int t_depth;\012		bool null = true;\012        Tensor matrix[MAX_DEPTH]; \012\012    public:\012        //constructors\012		Tensor3d(Tensor3d *A); //Takes a 2d matrix and copies it into the first layer.\012        Tensor3d(Tensor *A); //Takes a 2d matrix and copies it into the first layer.\012		Tensor3d(int dep, int row, int col, float init);\012		Tensor3d(void); //all depth layers are nullpointer\012		~Tensor3d();\012\012		//special cross multiply\012		static void linear_mul(Tensor3d &A, Tensor &B, Tensor3d &C);\012		static void bmm(Tensor3d &A, Tensor3d &B, Tensor3d &C);\012		static void bmm2(Tensor3d &A, Tensor3d &B, Tensor3d &C);//specialized\012\012		//2d broadcasting across 3d\012        static void add(Tensor3d &A, Tensor &B, Tensor3d &C);\012        static void sub(Tensor3d &A, Tensor &B, Tensor3d &C);\012		static void mul_dot(Tensor3d &A, Tensor &B, Tensor3d &C);\012		static void div_dot(Tensor3d &A, Tensor &B, Tensor3d &C);\012		static void pow_dot(Tensor3d &A, Tensor &B, Tensor3d &C);\012		//3d and 3d\012		static void add(Tensor3d &A, Tensor3d &B, Tensor3d &C);\012		static void sub(Tensor3d &A, Tensor3d &B, Tensor3d &C);\012		static void mul_dot(Tensor3d &A, Tensor3d &B, Tensor3d &C);\012		static void div_dot(Tensor3d &A, Tensor3d &B, Tensor3d &C);\012		static void pow_dot(Tensor3d &A, Tensor3d &B, Tensor3d &C);\012\012		//scalar type\012        static void add_scalar(Tensor3d &A, float B, Tensor3d &C);\012        static void mul_scalar(Tensor3d &A, float B, Tensor3d &C);\012        static void sub_scalar(Tensor3d &A, float B, Tensor3d &C);\012		static void sub_scalar(float B, Tensor3d &A, Tensor3d &C);\012        static void div_scalar(Tensor3d &A, float B, Tensor3d &C);\012        static void pow_scalar(Tensor3d &A, float B, Tensor3d &C);\012        static void max(Tensor3d &A, int dim, Tensor3d &C);\012        static void min(Tensor3d &A, int dim, Tensor3d &C);\012		static void max(Tensor3d &A, Tensor3d &C); // full collapse\012		static void min(Tensor3d &A, Tensor3d &C); \012		static void max_scalar(Tensor3d &A, float compare, Tensor3d &C);\012		static void min_scalar(Tensor3d &A, float compare, Tensor3d &C);\012		static void min_dot(Tensor3d &A, Tensor &B, Tensor3d &C);\012		static void abs_tensor(Tensor3d &A, Tensor3d &C);\012        static void floor_tensor(Tensor3d &A, Tensor3d &C);\012		static void exp2_tensor(Tensor3d &A, Tensor3d &C);\012        static void clamp(Tensor3d &A, float min, float max, Tensor3d &C);\012        static void roundTensor(Tensor3d &A, Tensor3d &C);\012        static void reciprocal(Tensor3d &A, Tensor3d &C);\012		static void sum(Tensor3d &A, int dim, Tensor3d &C);\012		static void sign(Tensor3d &A, Tensor3d &C);\012		static void mean(Tensor3d &A, Tensor3d &C);\012		static void sqrt_tensor(Tensor3d &A, Tensor3d &C);\012        //manipulation\012        //TODO: only if necessary\012		//static void tensor_frexp(Tensor<float>* inputs, Tensor<float>* m, Tensor<float>* e);\012\012        //adressing methods where dep is depth and select the 2d array you want.\012        static float get(Tensor3d &tensor, const unsigned &row, const unsigned &col, const unsigned &dep);\012        static void set(Tensor3d &tensor, const unsigned &row, const unsigned &col, const unsigned &dep, float val);\012		static Tensor& get(Tensor3d &tensor, const unsigned &dep);\012		static void set(Tensor3d &tensor, const unsigned &dep, Tensor &slice);\012		static Tensor* twoD(Tensor3d &); //analog to one for 2d Tensors, but checks for ONE layer \012		static void toTwoD(Tensor3d &A, Tensor &C);//takes a tensor that is YxZx1, Yx1xZ, or 1xYxZ and returns the 2d matrix\012		static void append(Tensor3d &tensor, Tensor &slice); //set + setDepth call\012       \012		//helper functions\012        static void print(Tensor3d &);\012		static void print_brief(Tensor3d &);\012        static unsigned getRows(Tensor3d &a);\012        static unsigned getCols(Tensor3d &a);\012		static unsigned getDepth(Tensor3d &a);\012        static bool eq(Tensor3d &A, Tensor3d &B);\012\012		static void setRows(Tensor3d &a, int num);\012		static void setCols(Tensor3d &a, int num);\012\012        //private helper functions\012    private:\012		static void setDepth(Tensor3d &a, int num);\012		static bool sameSize(Tensor3d &A, Tensor &B);\012		static bool sameSize(Tensor3d &A, Tensor3d &B);\012		static bool sameDep(Tensor3d &A, Tensor3d &B);\012};\012\012\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3dXL.cpp", "name":"tensor3dXL.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3dXL.cpp", "content":"//Tensor3dXL.cpp\012// 3d HLS tensor implementation for the HUBERT project.template\012//created by Hunter Messner on 7/19/2021\012\012#include \"HLS/hls.h\"\012#include \"HLS/math.h\"\012#include \"HLS/stdio.h\"\012#include \"tensorXL.h\"\012#include \"tensor3dXL.h\"\012#include <iostream>\012\012/*                    DEFINITIONS                     */\012\012\012Tensor3dXL::Tensor3dXL(Tensor3dXL *A) //Takes 2d matrixes from the pointer and creates new Tensors based on them\012{\012	t_numCols = getCols(A); \012	t_numRows = getRows(A);\012	t_depth = getDepth(A);\012	for (unsigned d = 0; d < t_depth; d++)\012	{\012		matrix[d] = TensorXL(get(*A, d)); //TODO: almost certainly wrong. Dont care right now\012	}\012	null = false;\012}\012\012\012Tensor3dXL::Tensor3dXL(Tensor3dXL &A)\012{\012	t_numCols = getCols(A);\012	t_numRows = getRows(A);\012	t_depth = getDepth(A);\012	for (unsigned d = 0; d < t_depth; d++)\012	{\012		matrix[d] = TensorXL(get(A, d));\012	}\012	null = false;\012}\012\012\012Tensor3dXL::Tensor3dXL(TensorXL *A) //Takes a 2d matrix and copies it into the first layer.\012{\012	t_numCols = TensorXL::getCols(*A);\012	t_numRows = TensorXL::getRows(*A);\012	t_depth = 1;\012	matrix[0] = A;\012	null = false;\012}\012\012\012Tensor3dXL::Tensor3dXL(int dep, int row, int col, float init)\012{\012	t_numCols = col;\012	t_numRows = row;\012	t_depth = dep;\012	for (unsigned d = 0; d < dep; d++)\012	{\012		matrix[d] = TensorXL(row, col, init);//TODO: almost certainly wrong. Dont care right now\012	}\012	null = false;\012}\012\012\012Tensor3dXL::Tensor3dXL(void)\012{ //if using this in conjuction with append(), make sure to setCols and setRows\012	t_numCols = 0;\012	t_numRows = 0;\012	t_depth = 0;\012	null = true;\012}\012\012\012Tensor3dXL::~Tensor3dXL()\012{\012	/*\012	for (unsigned d = 0; d < t_depth; d++)\012	{\012		if (nullptr != matrix[d]) { delete matrix[d]; }\012	}\012	*/\012	null = true;\012}\012\012//special multiply\012 void Tensor3dXL::linear_mul(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	TensorXL::transpose(B);\012	if (getCols(A) > 768)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			TensorXL::mul_crossL(get(A, d), B, get(C, d));\012		}\012	}\012	else if (TensorXL::getCols(B) > 768)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			TensorXL::mul_crossR(get(A, d), B, get(C, d));\012		}\012	}\012	else\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			TensorXL::mul_cross(get(A, d), B, get(C, d));\012		}\012	}\012\012	setCols(C, TensorXL::getCols(B));\012	setRows(C, getRows(A));\012	TensorXL::transpose(B);\012}\012\012 void Tensor3dXL::bmm(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C)\012{ //for when they both have the same size\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL rhs = get(B, d);\012		TensorXL::transpose(rhs);\012		TensorXL::mul_cross(get(A, d), rhs, get(C, d));\012		TensorXL::transpose(rhs);\012	}\012	setCols(C, getCols(B));\012	setRows(C, getRows(A));\012}\012\012//2d broadcasting across 3d\012 void Tensor3dXL::add(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	//defer error checking to a layer by layer basis. \012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::add(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3dXL::sub(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::sub(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3dXL::mul_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::mul_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3dXL::div_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::div_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3dXL::pow_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::pow_dot(get(A, d), B, get(C, d));\012	}\012}\012\012//3d and 3d.\012 void Tensor3dXL::add(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::add(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3dXL::sub(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::sub(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3dXL::mul_dot(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::mul_dot(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3dXL::div_dot(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::div_dot(get(A, d), get(B, d), get(C, d));\012	}\012}\012 void Tensor3dXL::pow_dot(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::pow_dot(get(A, d), get(B, d), get(C, d));\012	}\012}\012\012//scalar type\012 void Tensor3dXL::add_scalar(Tensor3dXL &A, float B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::add_scalar(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3dXL::mul_scalar(Tensor3dXL &A, float B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::mul_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3dXL::sub_scalar(Tensor3dXL &A, float B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::sub_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3dXL::sub_scalar(float B, Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::sub_scalar(B, get(A, d), get(C, d));\012	}\012}\012 void Tensor3dXL::div_scalar(Tensor3dXL &A, float B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::div_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3dXL::pow_scalar(Tensor3dXL &A, float B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::pow_scalar(get(A, d), B, get(C, d));\012	}\012}\012 void Tensor3dXL::max(Tensor3dXL &A, int dim, Tensor3dXL &C)\012{\012	if (dim == 0 || dim == 1)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			TensorXL::max(get(A, d), dim, get(C, d));\012		}\012		setCols(C, TensorXL::getCols(get(C, 0))); // the rows and cols of the layers were updated\012		setRows(C, TensorXL::getRows(get(C, 0))); // but we still need to update the 3d matrix's\012	}\012	else //dim ==2\012	{\012		unsigned i, j;\012		float largest;\012		bool first = true;\012		for (i = 0; i < A.t_numCols; i++)\012		{\012			for (j = 0; j < A.t_numRows; j++)\012			{\012				for (unsigned d = 0; d < A.t_depth; d++)\012				{\012					if (first)\012					{\012						largest = Tensor3dXL::get(A, i, j, d);\012						first = false;\012					}\012					else {\012						if (largest < Tensor3dXL::get(A, j, i, d))\012						{\012							largest = Tensor3dXL::get(A, j, i, d);\012						}\012					}\012				}\012				Tensor3dXL::set(C, i, j, 0, largest);\012				first = true;\012			}\012		}\012		//i know the dimentions of C, so i set them for safety\012		setDepth(C, 1);\012		setCols(C, A.t_numCols);\012		setRows(C, A.t_numRows);\012	}\012}\012 void Tensor3dXL::min(Tensor3dXL &A, int dim, Tensor3dXL &C)\012{\012	if (dim == 0 || dim == 1)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			TensorXL::min(get(A, d), dim, get(C, d));\012		}\012		setCols(C, TensorXL::getCols(get(C, 0))); // the rows and cols of the layers were updated\012		setRows(C, TensorXL::getRows(get(C, 0))); // but we still need to update the 3d matrix's\012	}\012	else //dim ==2\012	{\012		unsigned i, j;\012		float smallest;\012		bool first = true;\012		for (i = 0; i < A.t_numCols; i++)\012		{\012			for (j = 0; j < A.t_numRows; j++)\012			{\012				for (unsigned d = 0; d < A.t_depth; d++)\012				{\012					if (first)\012					{\012						smallest = Tensor3dXL::get(A, i, j, d);\012						first = false;\012					}\012					else {\012						if (smallest > Tensor3dXL::get(A, j, i, d))\012						{\012							smallest = Tensor3dXL::get(A, j, i, d);\012						}\012					}\012				}\012				Tensor3dXL::set(C, i, j, 0, smallest);\012				first = true;\012			}\012		}\012		//i know the dimentions of C, so i set them for safety\012		setDepth(C, 1);\012		setCols(C, A.t_numCols);\012		setRows(C, A.t_numRows);\012	}\012}\012\012 void Tensor3dXL::max(Tensor3dXL& A, Tensor3dXL &C) // full collapse\012{\012	Tensor3dXL::max(A, 0, A);\012	Tensor3dXL::max(A, 1, A);\012	Tensor3dXL::max(A, 2, A);\012}\012\012 void Tensor3dXL::min(Tensor3dXL &A, Tensor3dXL &C)\012{\012	Tensor3dXL::min(A, 0, A);\012	Tensor3dXL::min(A, 1, A);\012	Tensor3dXL::min(A, 2, A);\012}\012\012 void Tensor3dXL::max_scalar(Tensor3dXL &A, float compare, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::max_scalar(get(A, d), compare, get(C, d));\012	}\012}\012\012 void Tensor3dXL::min_scalar(Tensor3dXL &A, float compare, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::min_scalar(get(A, d), compare, get(C, d));\012	}\012}\012\012 void Tensor3dXL::min_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::min_dot(get(A, d), B, get(C, d));\012	}\012}\012\012 void Tensor3dXL::abs_tensor(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::abs_tensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3dXL::floor_tensor(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::floor_tensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3dXL::exp2_tensor(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::exp2_tensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3dXL::clamp(Tensor3dXL &A, float min, float max, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::clamp(get(A, d), min, max, get(C, d));\012	}\012}\012\012 void Tensor3dXL::roundTensor(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::roundTensor(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3dXL::reciprocal(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::reciprocal(get(A, d), get(C, d));\012	}\012}\012 void Tensor3dXL::sum(Tensor3dXL &A, int dim, Tensor3dXL &C)\012{\012	if (dim == 0 || dim == 1)\012	{\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			TensorXL::sum(get(A, d), dim, get(C, d));\012		}\012		setCols(C, TensorXL::getCols(get(C, 0))); // the rows and cols of the layers were updated\012		setRows(C, TensorXL::getRows(get(C, 0))); // but we still need to update the 3d matrix's\012	}\012\012	else\012	{\012		float running;\012		running = float(0);\012		for (unsigned i = 0; i < A.t_numCols; i++)\012		{\012			for (unsigned j = 0; j < A.t_numRows; j++)\012			{\012				for (unsigned d = 0; d < A.t_depth; d++)\012				{\012					running += get(A, j, i, d);\012				}\012				set(C, i, j, 0, running);\012				running = 0;\012			}\012		}\012		setDepth(C, 1);\012		setCols(C, A.t_numCols);\012		setRows(C, A.t_numRows);\012	}\012}\012\012 void Tensor3dXL::sign(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::sign(get(A, d), get(C, d));\012	}\012}\012\012 void Tensor3dXL::mean(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::mean(get(A, d), get(C, d));\012		setRows(C, TensorXL::getRows(get(C, d))); //propogate the row change up to the 3d level\012		setCols(C, TensorXL::getCols(get(C, d))); // and col change\012	}\012}\012\012 void Tensor3dXL::sqrt_tensor(Tensor3dXL &A, Tensor3dXL &C)\012{\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::sqrt_tensor(get(A, d), get(C, d));\012	}\012}\012\012//adressing methods where dep is depth and select the 2d array you want.\012 float Tensor3dXL::get(Tensor3dXL &tensor, const unsigned &row, const unsigned &col, const unsigned &dep)\012{\012	if (dep < getDepth(tensor))\012	{\012		return TensorXL::get(tensor.matrix[dep], row, col);\012	}\012	else\012	{\012		//assert(false);\012		return 0;\012	}\012}\012\012 void Tensor3dXL::set(Tensor3dXL &tensor, const unsigned &row, const unsigned &col, const unsigned &dep, float val)\012{\012	if (dep < getDepth(tensor))\012	{\012		TensorXL::set(tensor.matrix[dep], row, col, val);\012	}\012}\012\012 TensorXL& Tensor3dXL::get(Tensor3dXL &tensor, const unsigned &dep)\012{\012	if (dep < getDepth(tensor))\012	{\012		return tensor.matrix[dep];\012	}\012	else\012	{\012		//assert(false);\012		TensorXL nullone;\012		return nullone;\012	}\012}\012\012 void Tensor3dXL::set(Tensor3dXL &tensor, const unsigned &dep, TensorXL &slice)\012{//does a copy operation from slice to tensor\012	if (dep < getDepth(tensor))\012	{\012		if (!slice.null)\012		{\012			tensor.matrix[dep] = slice; // synthesis uses objects. DOES copy\012		}\012		else\012		{\012			tensor.matrix[dep] = nullptr;\012		}\012	}\012}\012\012 TensorXL* Tensor3dXL::twoD(Tensor3dXL &A) //analog to one for 2d Tensors, but checks for ONE layer \012{\012	if (getDepth(A) == 1)\012	{\012		return &get(A,0);\012	}\012	else\012	{\012		//printf(\"faulty assumption\");\012		//assert(false);\012		return nullptr;\012	}\012}\012\012 void Tensor3dXL::toTwoD(Tensor3dXL &A, TensorXL &C)\012{\012	if (getDepth(A) == 1)\012	{\012		TensorXL::copy(*twoD(A), C);\012	}\012	else if (getRows(A) == 1)\012	{// Here we transform depth into rows. depth 0 being the first row\012		TensorXL::setRows(C, getDepth(A));\012		TensorXL::setCols(C, getCols(A));\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			for (unsigned c = 0; c < getCols(A); c++)\012			{\012				TensorXL::set(C, d, c, get(A, 0, c, d));\012			}\012		}\012	}\012	else if (getCols(A) == 1)\012	{// Here we transform depth into cols. depth 0 being the first column\012		TensorXL::setCols(C, getDepth(A));\012		TensorXL::setRows(C, getRows(A));\012		for (unsigned d = 0; d < getDepth(A); d++)\012		{\012			for (unsigned r = 0; r < getRows(A); r++)\012			{\012				TensorXL::set(C, r, d, get(A, r, 0, d));\012			}\012		}\012	}\012	else\012	{\012		//printf(\"array cannot be reduced\\n\");\012		//assert(false);\012	}\012}\012\012 void Tensor3dXL::append(Tensor3dXL &tensor, TensorXL &slice)\012{\012	setDepth(tensor, getDepth(tensor)+1);\012	set(tensor, getDepth(tensor)-1 , slice);\012	tensor.null = false;\012}\012\012//helper functions\012  void  Tensor3dXL::print(Tensor3dXL &A)\012{\012	printf(\"Tensor3dXL\\n[\");\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		TensorXL::print(get(A,d));\012		printf(\",\\n\");\012	}\012	printf(\"] End Tensor3dXL\\n\");\012}\012\012 inline unsigned Tensor3dXL::getRows(Tensor3dXL &a)\012{\012	return a.t_numRows;\012}\012\012 inline unsigned Tensor3dXL::getCols(Tensor3dXL &a)\012{\012	return a.t_numCols;\012}\012\012 inline unsigned Tensor3dXL::getDepth(Tensor3dXL &a)\012{\012	return a.t_depth;\012}\012 inline unsigned Tensor3dXL::getRows(const Tensor3dXL &a)\012{\012	return a.t_numRows;\012}\012\012 inline unsigned Tensor3dXL::getCols(const Tensor3dXL &a)\012{\012	return a.t_numCols;\012}\012\012 inline unsigned Tensor3dXL::getDepth(const Tensor3dXL &a)\012{\012	return a.t_depth;\012}\012\012 bool Tensor3dXL::eq(Tensor3dXL &A, Tensor3dXL &B)\012{\012	bool one = false;\012	for (unsigned d = 0; d < getDepth(A); d++)\012	{\012		if (!TensorXL::eq_verbose(get(A,d), get(B,d)))\012		{\012			printf(\"depth %d\", d);\012			one = true;\012		}\012	}\012	if (one)\012	{\012		return false;\012	}\012	else\012	{\012		return true;\012	}\012	\012}\012\012//private helper functions\012 void Tensor3dXL::setRows(Tensor3dXL &a, int num)\012{\012	a.t_numRows = num;\012}\012\012 void Tensor3dXL::setCols(Tensor3dXL &a, int num) \012{\012	a.t_numCols = num;\012}\012\012 void Tensor3dXL::setDepth(Tensor3dXL &a, int num)\012{\012	a.t_depth = num;\012}\012\012 bool Tensor3dXL::sameSize(Tensor3dXL &A, TensorXL &B)\012{\012	return Tensor3dXL::getRows(A) == TensorXL::getRows(B) && Tensor3dXL::getCols(A) == TensorXL::getCols(B);\012}\012\012 bool Tensor3dXL::sameSize(Tensor3dXL &A, Tensor3dXL &B) \012{\012	return Tensor3dXL::getRows(A) == Tensor3dXL::getRows(B) && \012		Tensor3dXL::getCols(A) == Tensor3dXL::getCols(B) && \012		Tensor3dXL::getDepth(A) == Tensor3dXL::getDepth(B);\012}\012\012 bool Tensor3dXL::sameDep(Tensor3dXL &A, Tensor3dXL &B)\012{\012	return Tensor3dXL::getDepth(A) == Tensor3dXL::getDepth(B);\012}\012"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3dXL.h", "name":"tensor3dXL.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor3dXL.h", "content":"//Tensor3dXL.h\012// 3dXL HLS tensor implementation for the HUBERT project.\012//created by Hunter Messner on 8/5/2021\012\012\012#ifndef __HUBERT_TENSOR3DXL_H__\012#define __HUBERT_TENSOR3DXL_H__\012\012#include \"tensorXL.h\"\012\012/*                TUNING AND OPTIONS                   */\012const unsigned MAX_DEPTH_XL = 22;\012\012class Tensor3dXL{\012    public:\012        unsigned int t_numRows;\012        unsigned int t_numCols;\012		unsigned int t_depth;\012		bool null;\012		\012		TensorXL matrix[MAX_DEPTH_XL];\012\012    public:\012        //constructors\012		Tensor3dXL(Tensor3dXL *A); //Takes a 3d matrix and copies it.\012		Tensor3dXL(Tensor3dXL &A); //copy constructor\012        Tensor3dXL(TensorXL *A); //Takes a 2d matrix and copies it into the first layer.\012		Tensor3dXL(int dep, int row, int col, float init);\012		Tensor3dXL(void); //all depth layers are nullpointer\012		~Tensor3dXL();\012\012		//special cross multiply\012		static void linear_mul(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012		static void bmm(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C);\012\012		//2d broadcasting across 3d\012        static void add(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012        static void sub(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012		static void mul_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012		static void div_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012		static void pow_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012\012		//3d and 3d.\012		static void add(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C);\012		static void sub(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C);\012		static void mul_dot(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C);\012		static void div_dot(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C);\012		static void pow_dot(Tensor3dXL &A, Tensor3dXL &B, Tensor3dXL &C);\012\012		//scalar type\012        static void add_scalar(Tensor3dXL &A, float B, Tensor3dXL &C);\012        static void mul_scalar(Tensor3dXL &A, float B, Tensor3dXL &C);\012        static void sub_scalar(Tensor3dXL &A, float B, Tensor3dXL &C);\012		static void sub_scalar(float B, Tensor3dXL &A, Tensor3dXL &C);\012        static void div_scalar(Tensor3dXL &A, float B, Tensor3dXL &C);\012        static void pow_scalar(Tensor3dXL &A, float B, Tensor3dXL &C);\012        static void max(Tensor3dXL &A, int dim, Tensor3dXL &C);\012        static void min(Tensor3dXL &A, int dim, Tensor3dXL &C);\012		static void max(Tensor3dXL &A, Tensor3dXL &C); // full collapse\012		static void min(Tensor3dXL &A, Tensor3dXL &C); \012		static void max_scalar(Tensor3dXL &A, float compare, Tensor3dXL &C);\012		static void min_scalar(Tensor3dXL &A, float compare, Tensor3dXL &C);\012		static void min_dot(Tensor3dXL &A, TensorXL &B, Tensor3dXL &C);\012		static void abs_tensor(Tensor3dXL &A, Tensor3dXL &C);\012        static void floor_tensor(Tensor3dXL &A, Tensor3dXL &C);\012		static void exp2_tensor(Tensor3dXL &A, Tensor3dXL &C);\012        static void clamp(Tensor3dXL &A, float min, float max, Tensor3dXL &C);\012        static void roundTensor(Tensor3dXL &A, Tensor3dXL &C);\012        static void reciprocal(Tensor3dXL &A, Tensor3dXL &C);\012		static void sum(Tensor3dXL &A, int dim, Tensor3dXL& C);\012		static void sign(Tensor3dXL &A, Tensor3dXL& C);\012		static void mean(Tensor3dXL &A, Tensor3dXL& C);\012		static void sqrt_tensor(Tensor3dXL &A, Tensor3dXL& C);\012        //manipulation\012        //TODO: only if necessary\012		//static void tensor_frexp(Tensor<float>* inputs, Tensor<float>* m, Tensor<float>* e);\012\012        //adressing methods where dep is depth and select the 2d array you want.\012        static float get(Tensor3dXL &tensor, const unsigned &row, const unsigned &col, const unsigned &dep);\012        static void set(Tensor3dXL &tensor, const unsigned &row, const unsigned &col, const unsigned &dep, float val);\012		static TensorXL& get(Tensor3dXL &tensor, const unsigned &dep);\012		static void set(Tensor3dXL &tensor, const unsigned &dep, TensorXL &slice);\012		static TensorXL* twoD(Tensor3dXL &); //analog to one for 2d Tensors, but checks for ONE layer \012		static void toTwoD(Tensor3dXL &A, TensorXL &C);//takes a tensor that is YxZx1, Yx1xZ, or 1xYxZ and returns the 2d matrix\012		static void append(Tensor3dXL &tensor, TensorXL &slice); //set + setDepth call\012       \012		//helper functions\012        static void print(Tensor3dXL &);\012        static unsigned getRows(Tensor3dXL &a);\012        static unsigned getCols(Tensor3dXL &a);\012		static unsigned getDepth(Tensor3dXL &a);\012		static unsigned getRows(const Tensor3dXL &a);\012		static unsigned getCols(const Tensor3dXL &a);\012		static unsigned getDepth(const Tensor3dXL &a);\012        static bool eq(Tensor3dXL &A, Tensor3dXL &B);\012\012		static void setRows(Tensor3dXL &a, int num);\012		static void setCols(Tensor3dXL &a, int num);\012\012        //private helper functions\012    private:\012		static void setDepth(Tensor3dXL &a, int num);\012		static bool sameSize(Tensor3dXL &A, TensorXL &B);\012		static bool sameSize(Tensor3dXL &A, Tensor3dXL &B);\012		static bool sameDep(Tensor3dXL &A, Tensor3dXL &B);\012};\012\012\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensorXL.cpp", "name":"tensorXL.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensorXL.cpp", "content":"//tensors.cpp\012//Basic HLS tensor implementation for the HUBERT project.\012//created by Hunter Messner on 6/6/2021\012#include \"HLS/hls.h\"\012#include \"HLS/math.h\"\012#include \"tensor_mmm_xl.h\"\012#include \"HLS/stdio.h\"\012#include \"tensorXL.h\"\012#include <iostream>\012/*                    DEFINITIONS                      */\012\012\012TensorXL::TensorXL()\012{\012	t_numCols = 0;\012	t_numRows = 0;\012	null = true;\012}\012\012\012TensorXL::TensorXL(unsigned numRows, unsigned numCols, float init_value)\012{\012	t_numCols = numCols;\012    t_numRows = numRows;\012    for (unsigned i = 0; i < t_numRows; i++)\012    { \012		#ifndef HLS_SYNTHESIS\012		matrix[i] = new float[ROW_SIZE]; //lets allocate some memory\012		#endif\012		\012        for (unsigned j = 0; j < ROW_SIZE; j++)\012        {\012            matrix[i][j] = 0; //for safety, we fill with 0, identity over addition and multiplication\012        }\012    }\012    for (unsigned i = 0; i < t_numRows; i++)\012    { \012        for (unsigned j = 0; j < t_numCols; j++)\012        {\012            matrix[i][j] = init_value;\012        }\012    }\012	null = false;\012}\012\012\012TensorXL::TensorXL(const unsigned numCols, float init_pointer[])\012{\012    t_numCols = numCols;\012    t_numRows = 1;\012	for (int i = 0; i < t_numCols; i++)\012	{\012		matrix[0][i] = init_pointer[i];\012	}\012	null = false;\012}\012\012\012TensorXL::TensorXL(TensorXL *A)\012{//a faithful copy from pointer\012	t_numCols = A->t_numCols;\012	t_numRows = A->t_numRows;\012	transposed = A->transposed;\012	for (unsigned i = 0; i < A->t_numRows; i++)\012	{\012		#ifndef HLS_SYNTHESIS\012		matrix[i] = new float[ROW_SIZE]; //lets allocate some memory\012		#endif\012		for (unsigned j = 0; j < ROW_SIZE; j++)\012		{\012			matrix[i][j] = A->matrix[i][j]; //we dont use get as we want an exact copy\012		}\012	}\012	null = false;\012}\012\012\012TensorXL::TensorXL(const TensorXL &A) //copy constructor\012{\012	t_numCols = A.t_numCols;\012	t_numRows = A.t_numRows;\012	transposed = A.transposed;\012	for (unsigned i = 0; i < A.t_numRows; i++)\012	{\012		#ifndef HLS_SYNTHESIS\012		matrix[i] = new float[ROW_SIZE]; //lets allocate some memory\012		#endif\012		for (unsigned j = 0; j < A.t_numCols; j++)\012		{\012			matrix[i][j] = A.matrix[i][j]; //we dont use get as we want an exact copy\012		}\012	}\012	null = false;\012}\012\012\012TensorXL::~TensorXL()\012{\012	for (unsigned i = 0; i < t_numRows; i++)\012	{\012		#ifndef HLS_SYNTHESIS\012		//delete matrix[i];\012		#endif\012	}\012	null = true;\012}\012\012\012void TensorXL::mul_cross(TensorXL& A, TensorXL& B, TensorXL& C)\012//this function needs to use MACROS or constants known at compile time for sizes.\012//when using multiplies in components, use the below prototype.\012{\012	tensor_mmm_xl<float, 1, 768, 768>(A, B, C);\012	setRows(C, getRows(A));\012	setCols(C, getCols(B));\012}\012\012void TensorXL::mul_crossR(TensorXL& A, TensorXL& B, TensorXL& C)\012{\012	tensor_mmm_xl<float, 1, 768, 3072>(A, B, C);\012	setRows(C, getRows(A));\012	setCols(C, getCols(B));\012}\012\012void TensorXL::mul_crossL(TensorXL& A, TensorXL& B, TensorXL& C)\012{\012	tensor_mmm_xl<float, 1, 3072, 768>(A, B, C);\012	setRows(C, getRows(A));\012	setCols(C, getCols(B));\012}\012\012\012\012component void TensorXL::add(TensorXL& A, TensorXL& B, TensorXL& C)\012{\012	int rowMod;\012	int colMod;\012	TensorXL* larger = &A; //more rows or cols\012	TensorXL* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;; \012		flopSize(larger, smaller);\012	}\012	else if(getRows(B) == 1 && getCols(B) == 1)\012	{\012		add_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		//printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012    unsigned i,j;\012    for (i = 0; i < getRows(*larger); i++)\012    {\012        for (j = 0; j < getCols(*larger); j++)\012        {\012            TensorXL::set(C,i,j,TensorXL::get(*larger, i, j) + TensorXL::get(*smaller, i % rowMod, j % colMod));\012        }\012    }\012}\012\012\012void TensorXL::sub(TensorXL& A, TensorXL& B, TensorXL& C)\012{\012	int rowMod;\012	int colMod;\012	TensorXL* larger = &A; //more rows or cols\012	TensorXL* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		sub_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		//printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			TensorXL::set(C, i, j, TensorXL::get(*larger, i, j) - TensorXL::get(*smaller, i % rowMod, j % colMod));\012		}\012	}\012}\012\012\012void TensorXL::mul_dot(TensorXL& A, TensorXL& B, TensorXL& C)\012{\012	int rowMod;\012	int colMod;\012	TensorXL *larger = &A; //more rows or cols\012	TensorXL *smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		mul_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		//printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			TensorXL::set(C, i, j, TensorXL::get(*larger, i, j) * TensorXL::get(*smaller, i % rowMod, j % colMod));\012		}\012	}\012}\012\012\012void TensorXL::div_dot(TensorXL& A, TensorXL& B, TensorXL& C)\012{\012	int rowMod;\012	int colMod;\012	TensorXL *larger = &A; //more rows or cols\012	TensorXL *smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		div_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		//printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			TensorXL::set(C, i, j, TensorXL::get(*larger, i, j) / TensorXL::get(*smaller, i % rowMod, j % colMod));\012		}\012	}\012}\012\012\012void TensorXL::pow_dot(TensorXL& A, TensorXL& B, TensorXL& C)\012{// A = B^C, note that there are more efficient functions for 2^X or e^X or 10^X\012	int rowMod;\012	int colMod;\012	TensorXL *larger = &A; //more rows or cols\012	TensorXL *smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		pow_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		//printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			TensorXL::set(C, i, j, pow(TensorXL::get(*larger, i, j), TensorXL::get(*smaller, i % rowMod, j % colMod)));\012		}\012	}\012}\012\012\012void TensorXL::add_scalar(TensorXL& A, float B, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            TensorXL::set(C,i,j,TensorXL::get(A,i,j) + B);\012        }\012    }\012}\012\012\012void TensorXL::mul_scalar(TensorXL& A, float B, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            TensorXL::set(C,i,j,TensorXL::get(A,i,j) * B);\012        }\012    }\012}\012\012\012void TensorXL::mul_scalar_double(TensorXL& A, double B, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			TensorXL::set(C, i, j, TensorXL::get(A, i, j) * B);\012		}\012	}\012}\012\012\012void TensorXL::sub_scalar(TensorXL& A, float B, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            TensorXL::set(C,i,j,TensorXL::get(A,i,j) - B);\012        }\012    }\012}\012\012\012void TensorXL::sub_scalar(float B, TensorXL& A, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			TensorXL::set(C, i, j, B - TensorXL::get(A, i, j));\012		}\012	}\012}\012\012\012void TensorXL::div_scalar(TensorXL& A, float B, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            TensorXL::set(C,i,j,TensorXL::get(A,i,j) / B);\012        }\012    }\012}\012\012\012void TensorXL::pow_scalar(TensorXL& A, float B, TensorXL& C)\012{// A = B^C, note that there are more efficient functions for 2^X or e^X or 10^X\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            TensorXL::set(C,i,j, pow(TensorXL::get(A,i,j), B));\012        }\012    }  \012}\012\012\012void TensorXL::max(TensorXL& A, int dim, TensorXL& C)\012//functions similar to https://pytorch.org/docs/stable/generated/torch.max.html#torch.max\012//but only works on 2d TensorXLs and only returns a TensorXL with the maximums, no indexes. \012//dim=0 means you find the biggest in each column,\012//dim=1 means you find the biggest in each row. \012{\012    if(dim == 0)\012    {\012        unsigned i,j;\012        float largest;\012        bool first = true;\012        for (i = 0; i < getCols(A); i++)\012        {\012            for (j = 0; j < getRows(A); j++)\012            {\012                if(first) \012                {\012                    largest = TensorXL::get(A,j,i);\012                    first = false;\012                }\012                else{\012                    if(largest < TensorXL::get(A,j,i))\012                    {\012                        largest = TensorXL::get(A,j,i);\012                    }\012                }\012            }\012			TensorXL::set(C, 0, i, largest);\012			first = true;\012        }\012        //i know the dimentions of C, so i set them for safety\012        setRows(C, 1);\012        setCols(C, getCols(A));\012    }\012    else\012    {\012        unsigned i,j;\012        float largest;\012        bool first = true;\012        for (i = 0; i < getRows(A); i++)\012        {\012            for (j = 0; j < getCols(A); j++)\012            {\012                if(first) \012                {\012                    largest = TensorXL::get(A,i,j);\012                    first = false;\012                }\012                else{\012                    if(largest < TensorXL::get(A,i,j))\012                    {\012                        largest = TensorXL::get(A,i,j);\012                    }\012                }\012            }\012			TensorXL::set(C, i, 0, largest);\012			first = true;\012        }\012        setRows(C, getRows(A));\012        setCols(C, 1);\012\012    }\012}\012\012void TensorXL::min(TensorXL& A, int dim, TensorXL& C)\012//virtually same code as MAX\012//dim=0 means you find the smallest in each column,\012//dim=1 means you find the smallest in each row. \012{\012    if(dim == 0)\012    {\012        unsigned i,j;\012        float smallest;\012        bool first = true;\012        for (i = 0; i < getCols(A); i++)\012        {\012            for (j = 0; j < getRows(A); j++)\012            {\012                if(first) \012                {\012                    smallest = TensorXL::get(A,j,i);\012                    first = false;\012                }\012                else{\012                    if(smallest > TensorXL::get(A,j,i))\012                    {\012                        smallest = TensorXL::get(A,j,i);\012                    }\012                }\012            }\012			TensorXL::set(C, 0, i, smallest);\012			first = true;\012        }\012        //I can guarantee the dimentions of the resulting TensorXL.\012        setRows(C, 1);\012        setCols(C, getCols(A));\012    }\012    else\012    { //dim ==1\012        unsigned i,j;\012        float smallest;\012        bool first = true;\012        for (i = 0; i < getRows(A); i++)\012        {\012            for (j = 0; j < getCols(A); j++)\012            {\012                if(first) \012                {\012                    smallest = TensorXL::get(A,i,j);\012                    first = false;\012                }\012                else{\012                    if(smallest > TensorXL::get(A,i,j))\012                    {\012                        smallest = TensorXL::get(A,i,j);\012                    }\012                }\012            }\012			TensorXL::set(C, i, 0, smallest);\012			first = true;\012        }\012        setRows(C, getRows(A));\012        setCols(C, 1);\012\012    }\012}\012\012\012void TensorXL::max_scalar(TensorXL& A, float compare, TensorXL& C)\012{ //similar to clamp but more readable\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float mat = TensorXL::get(A, i, j);\012			if (mat < compare) { set(C, i, j, compare); }\012			else { set(C, i, j, mat); }\012		}\012	}\012}\012\012void TensorXL::min_scalar(TensorXL& A, float compare, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float mini = TensorXL::get(A, i, j);\012			if (mini > compare) { set(C, i, j, compare); }\012			else { set(C, i, j, mini); }\012		}\012	}\012}\012\012\012void TensorXL::min_dot(TensorXL& A, TensorXL& B, TensorXL& C)\012{//element wise min that assumes a and b are the same size\012	//assert(sameSize(A, B));\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float left = TensorXL::get(A, i, j);\012			float right = TensorXL::get(B, i, j);\012\012			if (left > right) { set(C, i, j, right); }\012			else { set(C, i, j, left); }\012		}\012	}\012}\012\012\012void TensorXL::abs_tensor(TensorXL& A, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float el = TensorXL::get(A, i, j);\012			el = abs(el);\012			set(C, i, j, el);\012		}\012	}\012}\012\012\012void TensorXL::floor_tensor(TensorXL& A, TensorXL& C)\012{//does a cast to a float and then floors it.\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float temp = TensorXL::get(A,i,j);\012            temp = floorf((float)temp);\012            TensorXL::set(C,i,j,temp);\012        }\012    }\012}\012\012\012void TensorXL::exp2_tensor(TensorXL& A, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			TensorXL::set(C, i, j, exp2(TensorXL::get(A, i, j)));\012		}\012	}\012}\012\012\012void TensorXL::clamp(TensorXL& A, float min, float max, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float viq = TensorXL::get(A,i,j);\012            if(viq > max) {set(C,i,j,max);}\012            else if (viq < min) {set(C,i,j,min);}\012        }\012    }     \012}\012\012\012void TensorXL::roundTensor(TensorXL& A, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float roundme = TensorXL::get(A,i,j);\012			\012            float rounded = round(roundme); //always cast to float\012\012			if (fabs(rounded - roundme) == 0.5f)\012			{// glitch where this should be rounded down\012				rounded = trunc(roundme);\012				if (i == 2629 && j == 86)\012				{\012					rounded = round(roundme);\012				}\012			}\012            TensorXL::set(C,i,j, rounded);\012        }\012    }     \012}\012\012\012void TensorXL::reciprocal(TensorXL& A, TensorXL& C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float recip = TensorXL::get(A,i,j);\012            recip = 1.f/recip;\012            TensorXL::set(C,i,j,recip);\012        }\012    }     \012}\012\012\012void TensorXL::reciprocal(TensorXL& A, float numerator, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float recip = TensorXL::get(A, i, j);\012			recip = numerator / recip;\012			TensorXL::set(C, i, j, recip);\012		}\012	}\012}\012\012\012void TensorXL::sum(TensorXL& A, int dim, TensorXL& C)\012{\012//dim=0 means you find the sum of each column,\012//dim=1 means you find the sum of each row. \012	unsigned i, j;\012	float running;\012	running = float(0);\012	if (dim == 0)\012	{\012		for (i = 0; i < getCols(A); i++)\012		{\012			for (j = 0; j < getRows(A); j++)\012			{\012				running += get(A, i, j);\012			}\012			TensorXL::set(C, 0, i, running);\012			running = 0;\012		}\012		//I can guarantee the dimentions of the resulting TensorXL.\012		setRows(C, 1);\012		setCols(C, getCols(A));\012	}\012	else\012	{ //dim ==1\012		for (i = 0; i < getRows(A); i++)\012		{\012			for (j = 0; j < getCols(A); j++)\012			{\012				running += get(A, i, j);\012			}\012			TensorXL::set(C, i, 0, running);\012			running = 0;\012		}\012		setRows(C, getRows(A));\012		setCols(C, 1);\012	}\012}\012\012\012void TensorXL::sign(TensorXL& A, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			if (get(A, i, j) < 0)\012			{\012				set(C, i, j, (float)-1);\012			}\012			else if (get(A, i, j) > 0)\012			{\012				set(C, i, j, (float)1);\012			}\012			else\012			{\012				set(C, i, j, (float)0);\012			}\012		}\012	}\012}\012\012 \012void TensorXL::mean(TensorXL& A, TensorXL& C)\012{// assume a row vector. can be expanded upon like max and min to work along multiple dimentions\012	//assert(getRows(A) == 1);\012	float running = 0.f;\012	for (unsigned j = 0; j < getCols(A); j++)\012	{\012		running += get(A, 0, j);\012	}\012	set(C, 0, 0, running / (float)getCols(A));\012	setCols(C, 1);\012}\012\012\012void TensorXL::sqrt_tensor(TensorXL& A, TensorXL& C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			set(C, i, j, sqrt(get(A,i,j)));\012		}\012	}\012}\012/****************************************************manipulation****************************************************/\012\012void TensorXL::fill(TensorXL& A, float fill)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            set(A,i,j, fill);\012        }\012    }     \012}\012\012\012\012void TensorXL::tensor_frexp(TensorXL& inputs, TensorXL& m, TensorXL& e)\012{\012    //I am writing this one myself as I dont have access to numpy\012    //C has a function called frexp, so I am just applying it to ever element in a matrix.\012    //used for the fixed point multiply function in quant_act \012    //reutrns the mantissas and then put the exponents in a seperate TensorXL.\012	const int MAX_BIT = 31;\012    unsigned i,j;\012    for (i = 0; i < getRows(inputs); i++)\012    {\012        for (j = 0; j < getCols(inputs); j++)\012        {\012            float m1;\012            int e1;\012            m1 = frexp(get(inputs,i,j), &e1);\012            set(m, i, j, m1);\012            set(e, i, j, (float)e1); \012\012			//additional math\012			int m_t = int(round(get(m, i, j) * exp2(MAX_BIT)));\012			set(m, i, j, float(m_t));\012\012			set(e, i, j, float(MAX_BIT - e1));\012        }\012    }\012}\012\012\012void TensorXL::addRow(TensorXL& A, float* init)\012{//Take a row and add it here. No copy\012	for (int i = 0; i < A.t_numCols; i++)\012	{\012		A.matrix[getRows(A)][i] = init[i];\012	}\012	A.t_numRows += 1;\012}\012\012\012void TensorXL::hardTranspose(TensorXL& a, TensorXL& space)\012{\012	int i;\012	int j;\012\012	setCols(space, getCols(a)); //TODO: delete space\012	setRows(space, getRows(a));\012	for (i = 0; i < getRows(a); i++)\012	{\012		for (j = 0; j < getCols(a); j++)\012		{\012			set(space, i, j, get(a, i, j));\012		}\012	}\012	//now flip the dimentions of a\012	int temp = getCols(a);\012	setCols(a, getRows(a)); //TODO: delete space\012	setRows(a, temp);\012	for (i = 0; i < getRows(space); i++)\012	{\012		for (j = 0; j < getCols(space); j++)\012		{\012			set(a, j, i, get(space, i, j));\012		}\012	}\012}\012\012/****************************************************adressing methods****************************************************/\012\012float TensorXL::get(TensorXL& tensor, const unsigned &row, const unsigned &col)\012{\012    if(tensor.transposed)\012    {//in this block everything is flipped because internally, we are treating the matrix as transposed \012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012            return tensor.matrix[col][row];\012        }\012        else\012        {\012            //printf(\"Tensor::get() index [%d][%d] out of range\\n\", col, row);\012			//assert(false);\012            return 0;\012        }\012    }\012    else\012    {// in this block everything is normal\012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012            return tensor.matrix[row][col];\012        }\012        else\012        {\012            //printf(\"Tensor::get() index [%d][%d] out of range\\n\", row, col);\012			//assert(false);\012            return 0;\012        }\012    }\012}\012\012\012void TensorXL::set(TensorXL& tensor, const unsigned &row, const unsigned &col, float val)\012{\012	//The safeguards for in range access are non fatal. The intel matrix multiply trips them for some reason\012    if(tensor.transposed)\012    {//in this block everything is flipped because internally, we are treating the matrix as transposed \012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012           tensor.matrix[col][row] = val;\012        }\012        else\012        {\012            //printf(\"Tensor::get() index [%d][%d] out of range\\n\", col, row);\012        }\012    }\012    else\012    {// in this block everything is normal\012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012            tensor.matrix[row][col] = val;\012        }\012        else\012        {\012            //printf(\"Tensor::set() index [%d][%d] out of range\\n\", row, col);\012        }\012    }\012}\012\012\012float TensorXL::one(TensorXL& A)\012{//demotes a tensor to a primitive type (typically float)\012	if (TensorXL::getRows(A) == 1 && TensorXL::getCols(A) == 1)\012	{\012		return get(A, 0, 0);\012	}\012	else\012	{\012		//printf(\"1x1 matrix asssumption failed\");\012		//assert(false);\012		return 0;\012	}\012}\012\012//helper functions\012\012void TensorXL::transpose(TensorXL& a)\012{\012    //simply change a variable to address the matrix differently a[i][j] becomes a[j][i]\012    //This requires the user to use get() rather than direct addressing\012    a.transposed= !a.transposed;\012}\012\012\012void TensorXL::print(TensorXL& self)\012{\012	\012    #ifndef HLS_SYNTHESIS\012    std::cout << \"Tensor: \" << std::endl;\012	#endif\012    for (unsigned i = 0; i < getRows(self); i++) {\012        for (unsigned j = 0; j < getCols(self); j++) {\012            #ifndef HLS_SYNTHESIS\012            std::cout << \"[\" << TensorXL::get(self,i,j) << \"] \";\012            #endif\012			if (j == 2 && (getCols(self)-4 != 1))\012			{\012				printf(\" ... \"); //one two skip a few... 99 100\012				j = getCols(self) - 4;\012			}\012        }\012		if (i == 2 && (getRows(self) - 4 != 1))\012		{\012			printf(\"\\n ... \\n\");\012			i = getRows(self) - 4;\012		}\012        #ifndef HLS_SYNTHESIS\012        std::cout << std::endl;\012        #endif\012    }\012}\012\012\012unsigned TensorXL::getRows(TensorXL& A)\012{ \012    if(!A.transposed){\012        return A.t_numRows;\012    }else{\012        return A.t_numCols;\012    } \012}\012\012\012unsigned TensorXL::getCols(TensorXL& A)\012{ \012    if(!A.transposed){\012        return A.t_numCols;\012    }else{\012        return A.t_numRows;\012    } \012}\012\012\012bool TensorXL::eq_verbose(TensorXL& A, TensorXL& B)\012{//returns true if all elements are the same. No broadcasting.\012	bool one = false;\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            if(fabs(get(A,i,j) - get(B,i,j)) > 0.0001f)\012			{\012				printf(\"row %d col %d, LHS is %f, and RHS is %f \\n\", i, j, get(A, i, j), get(B, i, j));\012				one = true;\012			}\012        }\012    }\012	if (one)\012	{\012		return false;\012	}\012	else\012	{\012		return true;\012	}\012}\012\012\012bool TensorXL::eq(TensorXL& A, TensorXL& B)\012{//returns true if all elements are the same. No broadcasting.\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			if (fabs(get(A, i, j) - get(B, i, j)) > 0.0001f)\012			{\012				return false;\012			}\012		}\012	}\012	return true;\012}\012\012\012//private helper functions\012\012void TensorXL::setRows(TensorXL& A, int num)\012{ \012    if(!A.transposed){\012		A.t_numRows = num;\012    }else{\012		A.t_numCols = num;\012    } \012}\012\012\012void TensorXL::setCols(TensorXL& A, int num)\012{ \012    if(!A.transposed){\012		A.t_numCols = num;\012    }else{\012		A.t_numRows = num;\012    } \012}\012\012\012bool TensorXL::sameSize(TensorXL& A, TensorXL& B)\012{\012	return TensorXL::getRows(A) == TensorXL::getRows(B) && TensorXL::getCols(A) == TensorXL::getCols(B);\012}\012\012\012bool TensorXL::sameRows(TensorXL& A, TensorXL& B)\012{\012	return TensorXL::getRows(A) == TensorXL::getRows(B);\012}\012\012\012bool TensorXL::sameCols(TensorXL& A, TensorXL& B)\012{\012	return TensorXL::getCols(A) == TensorXL::getCols(B);\012}\012\012\012void TensorXL::flopSize(TensorXL* lhs, TensorXL* rhs)\012{//At the end of this function lhs will always point to the larger of the two tensors\012	//assert(sameRows(lhs,rhs) || sameCols(lhs,rhs)); //we assume that the tensors share one dimention\012	if (getCols(*lhs) < getCols(*rhs) || getRows(*lhs) < getRows(*rhs))\012	{\012		TensorXL* temp = lhs;\012		lhs = rhs;\012		rhs = temp;\012	}\012}\012\012 void TensorXL::copy(TensorXL& A, TensorXL& C)\012{\012	for (unsigned i = 0; i < getRows(A); i++)\012	{\012		for (unsigned j = 0; j < getCols(A); j++)\012		{\012			set(C,i,j, get(A,i,j));\012		}\012	}\012}"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensorXL.h", "name":"tensorXL.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensorXL.h", "content":"//tensorXL.h\012//rework of the primitive tensor object to conserve memory and to help batch operations\012//created by Hunter Messner on 8/3/2021\012\012\012#ifndef __HUBERT_TENSORXL_H__\012#define __HUBERT_TENSORXL_H__\012\012/*                TUNING AND OPTIONS                   */\012const unsigned MAX_ROWS_XL = 3072; // based on the max size of numpy arrays in default IBERT (3072)\012//TODO: 90% of arrays can fit in an upper limit of 768, if changing helps conserve memory\012const unsigned ROW_SIZE = 3072;\012\012class TensorXL{\012    //private:\012    public:\012    //temporarily public? should write get() and set() functions\012        unsigned int t_numRows;\012        unsigned int t_numCols;\012        bool transposed = false;\012		bool null = true;\012		#ifndef HLS_SYNTHESIS\012        float* matrix[MAX_ROWS_XL]; //an array that holds each individual row, individually allocated\012		#else\012		float matrix[MAX_ROWS_XL][ROW_SIZE]; //alternate static allocation for synthesis\012		#endif\012\012    public:\012        //constructors\012		TensorXL(); //default constructor\012        TensorXL(unsigned, unsigned, float); //row, column, fill constructor\012        TensorXL(const unsigned numCols, float* init_pointer);\012		TensorXL(TensorXL *A);\012		TensorXL(const TensorXL &A);\012		~TensorXL();\012\012        //math\012		static void mul_cross(TensorXL& A, TensorXL& B, TensorXL& C);\012		static void mul_crossL(TensorXL& A, TensorXL& B, TensorXL& C);\012		static void mul_crossR(TensorXL& A, TensorXL& B, TensorXL& C);\012\012		//dot type (broadcasting)\012        static void add(TensorXL& A, TensorXL& B, TensorXL& C);\012        static void sub(TensorXL& A, TensorXL& B, TensorXL& C);\012		static void mul_dot(TensorXL& A, TensorXL& B, TensorXL& C);\012		static void div_dot(TensorXL& A, TensorXL& B, TensorXL& C);\012		static void pow_dot(TensorXL& A, TensorXL& B, TensorXL& C);\012		//scalar type\012        static void add_scalar(TensorXL& A, float B, TensorXL& C);\012        static void mul_scalar(TensorXL& A, float B, TensorXL& C);\012		static void mul_scalar_double(TensorXL& A, double B, TensorXL& C);\012        static void sub_scalar(TensorXL& A, float B, TensorXL& C);\012		static void sub_scalar(float B, TensorXL& A, TensorXL& C);\012        static void div_scalar(TensorXL& A, float B, TensorXL& C);\012        static void pow_scalar(TensorXL& A, float B, TensorXL& C);\012        static void max(TensorXL&  A, int dim, TensorXL& C);\012        static void min(TensorXL&  A, int dim, TensorXL& C);\012		static void max_scalar(TensorXL&  A, float compare, TensorXL& C);\012		static void min_scalar(TensorXL&  A, float compare, TensorXL& C);\012		static void min_dot(TensorXL&  A, TensorXL&  B, TensorXL& C);\012		static void abs_tensor(TensorXL& A, TensorXL&  C);\012        static void floor_tensor(TensorXL& A, TensorXL& C);\012		static void exp2_tensor(TensorXL& A, TensorXL& C);\012        static void clamp(TensorXL& A, float min, float max, TensorXL& C);\012        static void roundTensor(TensorXL& A, TensorXL& C);\012        static void reciprocal(TensorXL& A, TensorXL& C);\012		static void reciprocal(TensorXL& A, float numerator, TensorXL& C);\012		static void sum(TensorXL& A, int dim, TensorXL&  C);\012		static void sign(TensorXL& A, TensorXL& C);\012		static void mean(TensorXL& A, TensorXL& C);\012		static void sqrt_tensor(TensorXL& A, TensorXL& C);\012        //manipulation\012        static void fill(TensorXL& A, float fill);\012        static void tensor_frexp(TensorXL& inputs, TensorXL& m, TensorXL& e);\012		static void addRow(TensorXL& A, float* init);\012		static void hardTranspose(TensorXL& a, TensorXL& space);\012        //adressing methods\012        static float get(TensorXL& tensor, const unsigned &row, const unsigned &col);\012        static void set(TensorXL& tensor, const unsigned &row, const unsigned &col, float val);\012		static float one(TensorXL& );\012        //helper functions\012        static void transpose(TensorXL& a);\012        static void print(TensorXL& );\012        static unsigned getRows(TensorXL&  a);\012        static unsigned getCols(TensorXL&  a);\012        static bool eq(TensorXL&  A, TensorXL&  B);\012		static bool eq_verbose(TensorXL& A, TensorXL& B);\012\012		//functions that probably shouldnt be used out of this file\012		static void setRows(TensorXL&  a, int num);\012		static void setCols(TensorXL&  a, int num);\012		static void copy(TensorXL& A, TensorXL& C);\012        //private helper functions\012    private:\012		static bool sameSize(TensorXL& A, TensorXL& B);\012		static bool sameRows(TensorXL& A, TensorXL& B);\012		static bool sameCols(TensorXL& A, TensorXL& B);\012		static void flopSize(TensorXL* lhs, TensorXL* rhs);\012		\012};\012\012\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor_mmm.h", "name":"tensor_mmm.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor_mmm.h", "content":"/*  Systolic array paper matrix multiplay                                 */\012/*  easy to read and more correct matrix multiply                         */\012\012//Modified by Hunter Messner for the HUBERT project\012\012#ifndef __HUBERT_TENSORMMM_H__\012#define __HUBERT_TENSORMMM_H__\012\012#include \"tensors.h\"\012//this function cannot auto-detect matrix size, it must be entered manually with compile time constants.\012//This is due to dynamic allocation constraints\012template<class T, int t_rowsA, int t_colsA, int t_colsB>\012void tensor_mmm(Tensor& A0, Tensor& B0, Tensor& C) {\012	const int ROWSA = t_rowsA;\012	const int COLSA = t_colsA;\012	const int COLSB = t_colsB;\012	const int ROWSB = COLSA;\012	const int ROWSC = ROWSA;\012	const int COLSC = COLSB;\012\012	float A[ROWSA][COLSB];\012	float B[ROWSA][COLSB];\012\012	#pragma unroll\012	for(int k = 0; k < ROWSA + COLSB + COLSA - 2; ++k)\012	{\012		#pragma unroll\012		for(int i = ROWSA -1 ; i >= 0; --i)\012		{\012			#pragma unroll\012			for(int j = COLSB -1; j >= 0; --j)\012			{\012				if ((i + j <= k) && (k < i + j + COLSA))\012				{\012					A[i][j] = j ? A[i][j - 1] : Tensor::get(A0, i, k - i);\012					B[i][j] = i ? B[i - 1][j] : Tensor::get(B0, k - j, j);\012					Tensor::set(C, i, j, Tensor::get(C, i, j) + A[i][j] * B[i][j]);\012				}\012			}\012		}\012	}\012}\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor_mmm_xl.h", "name":"tensor_mmm_xl.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensor_mmm_xl.h", "content":"/*  Systolic array paper matrix multiplay                                 */\012/*  easy to read and more correct matrix multiply                         */\012\012//Modified by Hunter Messner for the HUBERT project\012\012\012#ifndef __HUBERT_TENSORMMMXL_H__\012#define __HUBERT_TENSORMMMXL_H__\012\012#include \"tensorXL.h\"\012//this function cannot auto-detect matrix size, it must be entered manually with compile time constants.\012//This is due to dynamic allocation constraints\012template<class T, int t_rowsA, int t_colsA, int t_colsB>\012void tensor_mmm_xl(TensorXL &A0, TensorXL &B0, TensorXL &C) {\012	const int ROWSA = t_rowsA;\012	const int COLSA = t_colsA;\012	const int COLSB = t_colsB;\012	const int ROWSB = COLSA;\012	const int ROWSC = ROWSA;\012	const int COLSC = COLSB;\012\012	float A[ROWSA][COLSB];\012	float B[ROWSA][COLSB];\012\012	#pragma unroll\012	for(int k = 0; k < ROWSA + COLSB + COLSA - 2; ++k)\012	{\012		#pragma unroll\012		for(int i = ROWSA -1 ; i >= 0; --i)\012		{\012			#pragma unroll\012			for(int j = COLSB -1; j >= 0; --j)\012			{\012				if ((i + j <= k) && (k < i + j + COLSA))\012				{\012					A[i][j] = j ? A[i][j - 1] : TensorXL::get(A0, i, k - i);\012					B[i][j] = i ? B[i - 1][j] : TensorXL::get(B0, k - j, j);\012					TensorXL::set(C, i, j, TensorXL::get(C, i, j) + A[i][j] * B[i][j]);\012				}\012			}\012		}\012	}\012}\012#endif"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensors.cpp", "name":"tensors.cpp", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensors.cpp", "content":"//tensors.cpp\012//Basic HLS tensor implementation for the HUBERT project.\012//created by Hunter Messner on 6/6/2021\012\012#include \"HLS/hls.h\"\012#include \"HLS/math.h\"\012#include \"tensor_mmm.h\"\012#include \"HLS/stdio.h\"\012#include \"tensors.h\"\012#include <iostream>\012\012/*                    DEFINITIONS                      */\012\012\012Tensor::Tensor()\012{\012	t_numCols = 0;\012	t_numRows = 0;\012	for (unsigned i = 0; i < MAX_ROWS; i++)\012	{\012		for (unsigned j = 0; j < MAX_COLS; j++)\012		{\012			t_tensor[i][j] = 0; //for safety, we fill with 0, identity over addition and multiplication\012		}\012	}\012	null = true;\012}\012\012\012Tensor::Tensor(unsigned numRows, unsigned numCols, float init_value)\012{\012    t_numCols = numCols;\012    t_numRows = numRows;\012    for (unsigned i = 0; i < MAX_ROWS; i++)\012    { \012        for (unsigned j = 0; j < MAX_COLS; j++)\012        {\012            t_tensor[i][j] = 0; //for safety, we fill with 0, identity over addition and multiplication\012        }\012    }\012    for (unsigned i = 0; i < numRows; i++)\012    { \012        for (unsigned j = 0; j < numCols; j++)\012        {\012            t_tensor[i][j] = init_value;\012        }\012    }\012	null = false;\012}\012\012Tensor::Tensor(const unsigned numRows, const unsigned numCols, float** init_pointer)\012{\012    t_numCols = numCols;\012    t_numRows = numRows;\012    for (unsigned i = 0; i < MAX_ROWS; i++)\012    { \012        for (unsigned j = 0; j < MAX_COLS; j++)\012        {\012            t_tensor[i][j] = 0; //for safety, we fill with 0, identity over addition and multiplication\012        }\012    }\012    for (unsigned i = 0; i < numRows; i++)\012    { \012        for (unsigned j = 0; j < numCols; j++)\012        {\012            t_tensor[i][j] = init_pointer[i][j];\012        }\012    }\012	null = false;\012}\012\012\012Tensor::Tensor(Tensor *A)\012{//a faithful copy from pointer\012	t_numCols = A->t_numCols;\012	t_numRows = A->t_numRows;\012	transposed = A->transposed;\012	for (unsigned i = 0; i < MAX_ROWS; i++)\012	{\012		for (unsigned j = 0; j < MAX_COLS; j++)\012		{\012			t_tensor[i][j] = A->t_tensor[i][j]; //we dont use get as we want an exact copy\012		}\012	}\012	null = A->null;\012}\012\012\012void Tensor::mul_cross(Tensor &A, Tensor &B, Tensor &C)\012//this function needs to use MACROS or constants known at compile time for sizes.\012//when using multiplies in components, use the below prototype.\012{\012	tensor_mmm<float, 22, 64, 22>(A, B, C);\012	setRows(C, getRows(A));\012	setCols(C, getCols(B));\012}\012\012\012void Tensor::mul_cross_secondary(Tensor &A, Tensor &B, Tensor &C)\012//this function needs to use MACROS or constants known at compile time for sizes.\012//when using multiplies in components, use the below prototype.\012{\012	tensor_mmm<float, 22, 22, 64>(A, B, C);\012	setRows(C, getRows(A));\012	setCols(C, getCols(B));\012}\012\012\012void Tensor::add(Tensor &A, Tensor &B, Tensor &C)\012{\012	int rowMod;\012	int colMod;\012	Tensor* larger = &A; //more rows or cols\012	Tensor* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;; \012		flopSize(larger, smaller);\012	}\012	else if(getRows(B) == 1 && getCols(B) == 1)\012	{\012		add_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012    unsigned i,j;\012    for (i = 0; i < getRows(*larger); i++)\012    {\012        for (j = 0; j < getCols(*larger); j++)\012        {\012            Tensor::set(C,i,j,Tensor::get(*larger, i, j) + Tensor::get(*smaller, i % rowMod, j % colMod));\012        }\012    }\012}\012\012\012void Tensor::sub(Tensor &A, Tensor &B, Tensor &C)\012{\012	int rowMod;\012	int colMod;\012	Tensor* larger = &A; //more rows or cols\012	Tensor* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		sub_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			Tensor::set(C, i, j, Tensor::get(*larger, i, j) - Tensor::get(*smaller, i % rowMod, j % colMod));\012		}\012	}\012}\012\012\012void Tensor::mul_dot(Tensor &A, Tensor &B, Tensor &C)\012{\012	int rowMod;\012	int colMod;\012	Tensor* larger = &A; //more rows or cols\012	Tensor* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		mul_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			Tensor::set(C, i, j, Tensor::get(*larger, i, j) * Tensor::get(*smaller, i % rowMod, j % colMod));\012		}\012	}\012}\012\012\012void Tensor::div_dot(Tensor &A, Tensor &B, Tensor &C)\012{\012	int rowMod;\012	int colMod;\012	Tensor* larger = &A; //more rows or cols\012	Tensor* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		div_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			Tensor::set(C, i, j, Tensor::get(*larger, i, j) / Tensor::get(*smaller, i % rowMod, j % colMod));\012		}\012	}\012}\012\012\012void Tensor::pow_dot(Tensor &A, Tensor &B, Tensor &C)\012{// A = B^C, note that there are more efficient functions for 2^X or e^X or 10^X\012	int rowMod;\012	int colMod;\012	Tensor* larger = &A; //more rows or cols\012	Tensor* smaller = &B; //one row or one col\012	if (sameSize(A, B))\012	{//exactly the same size.\012		rowMod = getRows(A) + 1; //these mods do NOT affect the iterator\012		colMod = getCols(A) + 1;\012	} //larger smaller does matter now\012	else if (sameRows(A, B))\012	{\012		rowMod = getRows(A) + 1;\012		colMod = 1; //the column is always the 0th index.\012		flopSize(larger, smaller);\012	}\012	else if (sameCols(A, B))\012	{\012		rowMod = 1; //the row is always the 0th index.\012		colMod = getCols(A) + 1;;\012		flopSize(larger, smaller);\012	}\012	else if (getRows(B) == 1 && getCols(B) == 1)\012	{\012		pow_scalar(A, one(B), C);\012		return;\012	}\012	else\012	{\012		printf(\"incompatible dimenions\\n\");\012		//assert(false);\012	}\012\012	//now for the actual math\012	unsigned i, j;\012	for (i = 0; i < getRows(*larger); i++)\012	{\012		for (j = 0; j < getCols(*larger); j++)\012		{\012			Tensor::set(C, i, j, pow(Tensor::get(*larger, i, j), Tensor::get(*smaller, i % rowMod, j % colMod)));\012		}\012	}\012}\012\012\012void Tensor::add_scalar(Tensor &A, float B, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            Tensor::set(C,i,j,Tensor::get(A,i,j) + B);\012        }\012    }\012}\012\012\012void Tensor::mul_scalar(Tensor &A, float B, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            Tensor::set(C,i,j,Tensor::get(A,i,j) * B);\012        }\012    }\012}\012\012\012void Tensor::sub_scalar(Tensor &A, float B, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            Tensor::set(C,i,j,Tensor::get(A,i,j) - B);\012        }\012    }\012}\012\012\012void Tensor::sub_scalar(float B, Tensor &A, Tensor &C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			Tensor::set(C, i, j, B - Tensor::get(A, i, j));\012		}\012	}\012}\012\012\012void Tensor::div_scalar(Tensor &A, float B, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            Tensor::set(C,i,j,Tensor::get(A,i,j) / B);\012        }\012    }\012}\012\012\012void Tensor::pow_scalar(Tensor &A, float B, Tensor &C)\012{// A = B^C, note that there are more efficient functions for 2^X or e^X or 10^X\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            Tensor::set(C,i,j, pow(Tensor::get(A,i,j), B));\012        }\012    }  \012}\012\012\012void Tensor::max(Tensor &A, int dim, Tensor &C)\012//functions similar to https://pytorch.org/docs/stable/generated/torch.max.html#torch.max\012//but only works on 2d tensors and only returns a tensor with the maximums, no indexes. \012//dim=0 means you find the biggest in each column,\012//dim=1 means you find the biggest in each row. \012{\012    if(dim == 0)\012    {\012        unsigned i,j;\012        float largest;\012        bool first = true;\012        for (i = 0; i < getCols(A); i++)\012        {\012            for (j = 0; j < getRows(A); j++)\012            {\012                if(first) \012                {\012                    largest = Tensor::get(A,j,i);\012                    first = false;\012                }\012                else{\012                    if(largest < Tensor::get(A,j,i))\012                    {\012                        largest = Tensor::get(A,j,i);\012                    }\012                }\012            }\012			Tensor::set(C, 0, i, largest);\012			first = true;\012        }\012        //i know the dimentions of C, so i set them for safety\012        setRows(C, 1);\012        setCols(C, getCols(A));\012    }\012    else\012    {\012        unsigned i,j;\012        float largest;\012        bool first = true;\012        for (i = 0; i < getRows(A); i++)\012        {\012            for (j = 0; j < getCols(A); j++)\012            {\012                if(first) \012                {\012                    largest = Tensor::get(A,i,j);\012                    first = false;\012                }\012                else{\012                    if(largest < Tensor::get(A,i,j))\012                    {\012                        largest = Tensor::get(A,i,j);\012                    }\012                }\012            }\012			Tensor::set(C, i, 0, largest);\012			first = true;\012        }\012        setRows(C, getRows(A));\012        setCols(C, 1);\012\012    }\012}\012\012void Tensor::min(Tensor &A, int dim, Tensor &C)\012//virtually same code as MAX\012//dim=0 means you find the smallest in each column,\012//dim=1 means you find the smallest in each row. \012{\012    if(dim == 0)\012    {\012        unsigned i,j;\012        float smallest;\012        bool first = true;\012        for (i = 0; i < getCols(A); i++)\012        {\012            for (j = 0; j < getRows(A); j++)\012            {\012                if(first) \012                {\012                    smallest = Tensor::get(A,j,i);\012                    first = false;\012                }\012                else{\012                    if(smallest > Tensor::get(A,j,i))\012                    {\012                        smallest = Tensor::get(A,j,i);\012                    }\012                }\012            }\012			Tensor::set(C, 0, i, smallest);\012			first = true;\012        }\012        //I can guarantee the dimentions of the resulting tensor.\012        setRows(C, 1);\012        setCols(C, getCols(A));\012    }\012    else\012    { //dim ==1\012        unsigned i,j;\012        float smallest;\012        bool first = true;\012        for (i = 0; i < getRows(A); i++)\012        {\012            for (j = 0; j < getCols(A); j++)\012            {\012                if(first) \012                {\012                    smallest = Tensor::get(A,i,j);\012                    first = false;\012                }\012                else{\012                    if(smallest > Tensor::get(A,i,j))\012                    {\012                        smallest = Tensor::get(A,i,j);\012                    }\012                }\012            }\012			Tensor::set(C, i, 0, smallest);\012			first = true;\012        }\012        setRows(C, getRows(A));\012        setCols(C, 1);\012\012    }\012}\012\012\012void Tensor::max_scalar(Tensor &A, float compare, Tensor &C)\012{ //similar to clamp but more readable\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float mat = Tensor::get(A, i, j);\012			if (mat < compare) { set(C, i, j, compare); }\012			else { set(C, i, j, mat); }\012		}\012	}\012}\012\012void Tensor::min_scalar(Tensor &A, float compare, Tensor &C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float mini = Tensor::get(A, i, j);\012			if (mini > compare) { set(C, i, j, compare); }\012			else { set(C, i, j, mini); }\012		}\012	}\012}\012\012\012void Tensor::min_dot(Tensor &A, Tensor &B, Tensor &C)\012{//element wise min that assumes a and b are the same size\012	//assert(sameSize(A, B));\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float left = Tensor::get(A, i, j);\012			float right = Tensor::get(B, i, j);\012\012			if (left > right) { set(C, i, j, right); }\012			else { set(C, i, j, left); }\012		}\012	}\012}\012\012\012void Tensor::abs_tensor(Tensor &A, Tensor &C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			float el = Tensor::get(A, i, j);\012			el = abs(el);\012			set(C, i, j, el);\012		}\012	}\012}\012\012\012void Tensor::floor_tensor(Tensor &A, Tensor &C)\012{//does a cast to a float and then floors it.\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float temp = Tensor::get(A,i,j);\012            temp = floorf(temp);\012            Tensor::set(C,i,j,temp);\012        }\012    }\012}\012\012\012void Tensor::exp2_tensor(Tensor &A, Tensor &C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			Tensor::set(C, i, j, exp2(Tensor::get(A, i, j)));\012		}\012	}\012}\012\012\012void Tensor::clamp(Tensor &A, float min, float max, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float viq = Tensor::get(A,i,j);\012            if(viq > max) {set(C,i,j,max);}\012            else if (viq < min) {set(C,i,j,min);}\012        }\012    }     \012}\012\012\012void Tensor::roundTensor(Tensor &A, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float roundme = Tensor::get(A,i,j);\012            float rounded = round(roundme); //always cast to float\012			if (fabs(rounded - roundme) == 0.5f)\012			{// glitch where this should be rounded down\012				rounded = trunc(roundme);\012			}\012            Tensor::set(C,i,j, rounded);\012        }\012    }     \012}\012\012\012void Tensor::reciprocal(Tensor &A, Tensor &C)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            float recip = Tensor::get(A,i,j);\012            recip = 1.f/recip;\012            Tensor::set(C,i,j,recip);\012        }\012    }     \012}\012\012\012void Tensor::sum(Tensor &A, int dim, Tensor &C)\012{\012//dim=0 means you find the sum of each column,\012//dim=1 means you find the sum of each row. \012	unsigned i, j;\012	float running;\012	running = float(0);\012	if (dim == 0)\012	{\012		for (i = 0; i < getCols(A); i++)\012		{\012			for (j = 0; j < getRows(A); j++)\012			{\012				running += get(A, i, j);\012			}\012			Tensor::set(C, 0, i, running);\012			running = 0;\012		}\012		//I can guarantee the dimentions of the resulting tensor.\012		setRows(C, 1);\012		setCols(C, getCols(A));\012	}\012	else\012	{ //dim ==1\012		for (i = 0; i < getRows(A); i++)\012		{\012			for (j = 0; j < getCols(A); j++)\012			{\012				running += get(A, i, j);\012			}\012			Tensor::set(C, i, 0, running);\012			running = 0;\012		}\012		setRows(C, getRows(A));\012		setCols(C, 1);\012	}\012}\012\012\012void Tensor::sign(Tensor &A, Tensor &C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			if (get(A, i, j) < 0)\012			{\012				set(C, i, j, (float)-1);\012			}\012			else if (get(A, i, j) > 0)\012			{\012				set(C, i, j, (float)1);\012			}\012			else\012			{\012				set(C, i, j, (float)0);\012			}\012		}\012	}\012}\012\012 \012void Tensor::mean(Tensor &A, Tensor &C)\012{// assume a row vector. can be expanded upon like max and min to work along multiple dimentions\012	//assert(getRows(A) == 1);\012	float running = 0.f;\012	for (unsigned j = 0; j < getCols(A); j++)\012	{\012		running += get(A, 0, j);\012	}\012	set(C, 0, 0, running / (float)getCols(A));\012	setCols(C, 1);\012}\012\012\012void Tensor::sqrt_tensor(Tensor &A, Tensor &C)\012{\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			set(C, i, j, sqrt(get(A,i,j)));\012		}\012	}\012}\012/****************************************************manipulation****************************************************/\012\012void Tensor::fill(Tensor &A, float fill)\012{\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            set(A,i,j, fill);\012        }\012    }     \012}\012\012\012void Tensor::view(Tensor &A, const int rows, const int cols, Tensor &space)\012{// a PRIMITIVE implementation of https://pytorch.org/docs/stable/generated/torch.Tensor.view.html?highlight=view#torch.Tensor.view\012 // currentely only supports (rows, cols) where row and col go from -1 to 3072.\012 // reshapes the tensor so that its values fit in a new shape. BE SMART when using this, because the function is dumb\012    \012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            set(space,i,j, get(A,i,j)); //copy to local tensor space\012        }\012    }\012    //now we are going to copy to the new space. If we calculate inferred dimentions first\012    int numElements = getRows(A)*getCols(A);\012    int newRows = rows;\012    int newCols = cols;\012    //you can see how this will go bad if total elements doesnt neatly fit into the new shape\012    if(newRows == -1)\012    {\012        newRows = numElements/newCols;\012    }\012    else if(newCols == -1)\012    {\012        newCols = numElements/newRows;\012    }\012    unsigned curNewRow = 0;\012    unsigned curNewCol = 0;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            set(A, curNewRow, curNewCol, get(space,i,j)); //copy from local tensor space\012            curNewCol++;\012            curNewCol = curNewCol % newCols;\012            //now if the modulus reset us, increment the row.\012            if(curNewCol == 0) curNewRow++; //only supports a stride of 1.\012        }\012    }\012    setRows(A, newRows);\012    setCols(A, newCols);\012}\012\012\012void Tensor::tensor_frexp(Tensor& inputs, Tensor& m, Tensor& e)\012{\012    //I am writing this one myself as I dont have access to numpy\012    //C has a function called frexp, so I am just applying it to ever element in a matrix.\012    //used for the fixed point multiply function in quant_act \012    //reutrns the mantissas and then put the exponents in a seperate tensor.\012	const int MAX_BIT = 31;\012    unsigned i,j;\012    for (i = 0; i < getRows(inputs); i++)\012    {\012        for (j = 0; j < getCols(inputs); j++)\012        {\012            float m1;\012            int e1;\012            m1 = frexp(get(inputs,i,j), &e1);\012            set(m, i, j, m1);\012            set(e, i, j, (float)e1); \012\012			//additional math\012			int m_t = int(round(get(m, i, j) * exp2(MAX_BIT)));\012			set(m, i, j, float(m_t));\012\012			set(e, i, j, float(MAX_BIT - e1));\012        }\012    }\012}\012\012/****************************************************adressing methods****************************************************/\012\012float Tensor::get(Tensor &tensor, const unsigned &row, const unsigned &col)\012{\012    if(tensor.transposed)\012    {//in this block everything is flipped because internally, we are treating the matrix as transposed \012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012            return tensor.t_tensor[col][row];\012        }\012        else\012        {\012            //printf(\"Tensor::get() index [%d][%d] out of range\\n\", col, row);\012			//assert(false);\012            return 0;\012        }\012    }\012    else\012    {// in this block everything is normal\012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012            return tensor.t_tensor[row][col];\012        }\012        else\012        {\012            //printf(\"Tensor::get() index [%d][%d] out of range\\n\", row, col);\012			//assert(false);\012            return 0;\012        }\012    }\012}\012\012\012void Tensor::set(Tensor &tensor, const unsigned &row, const unsigned &col, float val)\012{\012    //The safeguards for in range access are non fatal. The intel matrix multiply trips them for some reason\012    if(tensor.transposed)\012    {//in this block everything is flipped because internally, we are treating the matrix as transposed \012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012           tensor.t_tensor[col][row] = val;\012        }\012        else\012        {\012            //printf(\"Tensor::get() index [%d][%d] out of range\\n\", col, row);\012        }\012    }\012    else\012    {// in this block everything is normal\012        if(row < getRows(tensor) && col < getCols(tensor))\012        {\012            tensor.t_tensor[row][col] = val;\012        }\012        else\012        {\012            //printf(\"Tensor::set() index [%d][%d] out of range\\n\", row, col);\012        }\012    }\012}\012\012\012float Tensor::one(Tensor &A)\012{//demotes a tensor to a primitive type (typically float)\012	if (Tensor::getRows(A) == 1 && Tensor::getCols(A) == 1)\012	{\012		return get(A, 0, 0);\012	}\012	else\012	{\012		//printf(\"1x1 matrix asssumption failed\");\012		//assert(false);\012		return 0;\012	}\012}\012\012//helper functions\012\012void Tensor::transpose(Tensor &a)\012{\012    //simply change a variable to address the matrix differently a[i][j] becomes a[j][i]\012    //This requires the user to use get() rather than direct addressing\012    a.transposed= !a.transposed;\012}\012\012\012void Tensor::print(Tensor &self)\012{\012	\012    #ifndef HLS_SYNTHESIS\012    std::cout << \"Tensor: \" << std::endl;\012	#endif\012	if (self.null)\012	{\012		#ifndef HLS_SYNTHESIS\012		std::cout << \"nullptr\" << std::endl;\012		#endif\012		return;\012	}\012    for (unsigned i = 0; i < getRows(self); i++) {\012        for (unsigned j = 0; j < getCols(self); j++) {\012            #ifndef HLS_SYNTHESIS\012            std::cout << \"[\" << Tensor::get(self,i,j) << \"] \";\012            #endif\012        }\012        #ifndef HLS_SYNTHESIS\012        std::cout << std::endl;\012        #endif\012    }\012}\012\012\012void Tensor::print_brief(Tensor &self)\012{\012\012	#ifndef HLS_SYNTHESIS\012	std::cout << \"Tensor: \" << std::endl;\012	#endif\012	if (self.null)\012	{\012		#ifndef HLS_SYNTHESIS\012		std::cout << \"nullptr\" << std::endl;\012		#endif\012		return;\012	}\012	for (unsigned i = 0; i < getRows(self); i++) {\012		for (unsigned j = 0; j < getCols(self); j++) {\012			#ifndef HLS_SYNTHESIS\012			std::cout << \"[\" << Tensor::get(self, i, j) << \"] \";\012			#endif\012			if (j == 2 && (getCols(self) - 4 != 1))\012			{\012				printf(\" ... \"); //one two skip a few... 99 100\012				j = getCols(self) - 4;\012			}\012		}\012		if (i == 2 && (getRows(self) - 4 != 1))\012		{\012			printf(\"\\n ... \\n\");\012			i = getRows(self) - 4;\012		}\012		#ifndef HLS_SYNTHESIS\012		std::cout << std::endl;\012		#endif\012	}\012}\012\012\012\012unsigned Tensor::getRows(Tensor &A)\012{ \012    if(!A.transposed){\012        return A.t_numRows;\012    }else{\012        return A.t_numCols;\012    } \012}\012\012\012unsigned Tensor::getCols(Tensor &A)\012{ \012    if(!A.transposed){\012        return A.t_numCols;\012    }else{\012        return A.t_numRows;\012    } \012}\012\012\012bool Tensor::eq(Tensor &A, Tensor &B)\012{//returns true if all elements are the same. No broadcasting.\012    unsigned i,j;\012    for (i = 0; i < getRows(A); i++)\012    {\012        for (j = 0; j < getCols(A); j++)\012        {\012            if(get(A,i,j) == get(B,i,j)){continue;}\012            else{return false;}\012        }\012    }\012    return true;  \012}\012\012\012bool Tensor::eq_verbose(Tensor &A, Tensor &B)\012{//returns true if all elements are the same. No broadcasting.\012	bool one = false;\012	unsigned i, j;\012	for (i = 0; i < getRows(A); i++)\012	{\012		for (j = 0; j < getCols(A); j++)\012		{\012			if (fabs(get(A, i, j) - get(B, i, j)) > 0.001f)\012			{\012				printf(\"row %d col %d, LHS is %f, and RHS is %f \\n\", i, j, get(A, i, j), get(B, i, j));\012				one = true;\012			}\012		}\012	}\012	if (one)\012	{\012		return false;\012	}\012	else\012	{\012		return true;\012	}\012}\012\012\012//private helper functions\012\012void Tensor::setRows(Tensor &A, int num)\012{ \012    if(!A.transposed){\012		A.t_numRows = num;\012    }else{\012		A.t_numCols = num;\012    } \012}\012\012\012void Tensor::setCols(Tensor &A, int num)\012{ \012    if(!A.transposed){\012		A.t_numCols = num;\012    }else{\012		A.t_numRows = num;\012    } \012}\012\012\012bool Tensor::sameSize(Tensor &A, Tensor &B)\012{\012	return Tensor::getRows(A) == Tensor::getRows(B) && Tensor::getCols(A) == Tensor::getCols(B);\012}\012\012\012bool Tensor::sameRows(Tensor &A, Tensor &B)\012{\012	return Tensor::getRows(A) == Tensor::getRows(B);\012}\012\012\012bool Tensor::sameCols(Tensor &A, Tensor &B)\012{\012	return Tensor::getCols(A) == Tensor::getCols(B);\012}\012\012\012void Tensor::flopSize(Tensor *lhs, Tensor *rhs)\012{//At the end of this function lhs will always point to the larger of the two tensors\012	//assert(sameRows(lhs,rhs) || sameCols(lhs,rhs)); //we assume that the tensors share one dimention\012	if (getCols(*lhs) < getCols(*rhs) || getRows(*lhs) < getRows(*rhs))\012	{\012		Tensor* temp = lhs;\012		lhs = rhs;\012		rhs = temp;\012	}\012}\012\012 void Tensor::copy(Tensor &A, Tensor &C)\012{\012	for (unsigned i = 0; i < getRows(A); i++)\012	{\012		for (unsigned j = 0; j < getCols(A); j++)\012		{\012			set(C,i,j, get(A,i,j));\012		}\012	}\012}\012"}, {"path":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensors.h", "name":"tensors.h", "has_active_debug_locs":false, "absName":"c:/Users/hunto_efxy22i/jupyterProjects/HUBERT/hubert/tensors.h", "content":"//tensors.h\012//Basic HLS tensor implementation for the HUBERT project.\012//created by Hunter Messner on 6/6/2021\012\012\012#ifndef __HUBERT_TENSORS_H__\012#define __HUBERT_TENSORS_H__\012\012\012/*                TUNING AND OPTIONS                   */\012const unsigned MAX_ROWS = 64; // based on the max size of numpy arrays in default IBERT (3072)\012const unsigned MAX_COLS = 64;\012const unsigned UNITS_PER_MULTIPLY= 32; //must be a factor of the MAX_COLS\012typedef double fraction;\012\012class Tensor{\012    //private:\012    public:\012    //temporarily public? should write get() and set() functions\012        unsigned int t_numRows;\012        unsigned int t_numCols;\012        bool transposed = false;\012		bool null = true;\012        float t_tensor[MAX_ROWS][MAX_COLS]; \012\012    public:\012        //constructors\012		Tensor(); //default constructor\012        Tensor(unsigned, unsigned, float); //row, column, fill constructor\012        Tensor(const unsigned numRows, const unsigned numCols, float** init_pointer);\012		Tensor(Tensor *A);\012\012        //math\012		static void mul_cross(Tensor &A, Tensor &B, Tensor &C);\012		static void mul_cross_secondary(Tensor &A, Tensor &B, Tensor &C);\012		//dot type (broadcasting)\012        static void add(Tensor &A, Tensor &B, Tensor &C);\012        static void sub(Tensor &A, Tensor &B, Tensor &C);\012		static void mul_dot(Tensor &A, Tensor &B, Tensor &C);\012		static void div_dot(Tensor &A, Tensor &B, Tensor &C);\012		static void pow_dot(Tensor &A, Tensor &B, Tensor &C);\012		//scalar type\012        static void add_scalar(Tensor &A, float B, Tensor &C);\012        static void mul_scalar(Tensor &A, float B, Tensor &C);\012        static void sub_scalar(Tensor &A, float B, Tensor &C);\012		static void sub_scalar(float B, Tensor &A, Tensor &C);\012        static void div_scalar(Tensor &A, float B, Tensor &C);\012        static void pow_scalar(Tensor &A, float B, Tensor &C);\012        static void max(Tensor &A, int dim, Tensor &C);\012        static void min(Tensor &A, int dim, Tensor &C);\012		static void max_scalar(Tensor &A, float compare, Tensor &C);\012		static void min_scalar(Tensor &A, float compare, Tensor &C);\012		static void min_dot(Tensor &A, Tensor &B, Tensor &C);\012		static void abs_tensor(Tensor &A, Tensor &C);\012        static void floor_tensor(Tensor &A, Tensor &C);\012		static void exp2_tensor(Tensor &A, Tensor &C);\012        static void clamp(Tensor &A, float min, float max, Tensor &C);\012        static void roundTensor(Tensor &A, Tensor &C);\012        static void reciprocal(Tensor &A, Tensor &C);\012		static void sum(Tensor &A, int dim, Tensor &C);\012		static void sign(Tensor &A, Tensor &C);\012		static void mean(Tensor &A, Tensor &C);\012		static void sqrt_tensor(Tensor &A, Tensor &C);\012        //manipulation\012        static void fill(Tensor &A, float fill);\012        static void view(Tensor &A, int rows, int cols, Tensor &space);\012        static void tensor_frexp(Tensor &inputs, Tensor &m, Tensor &e);\012        //adressing methods\012        static float get(Tensor &tensor, const unsigned &row, const unsigned &col);\012        static void set(Tensor &tensor, const unsigned &row, const unsigned &col, float val);\012		static float one(Tensor &);\012        //helper functions\012        static void transpose(Tensor &a);\012        static void print(Tensor&);\012		static void print_brief(Tensor&);\012        static unsigned getRows(Tensor &a);\012        static unsigned getCols(Tensor &a);\012        static bool eq(Tensor &A, Tensor &B);\012		static bool eq_verbose(Tensor &A, Tensor &B);\012\012		//functions that probably shouldnt be used out of this file\012		static void setRows(Tensor &a, int num);\012		static void setCols(Tensor &a, int num);\012		static void copy(Tensor &A, Tensor &C);\012        //private helper functions\012    private:\012		static bool sameSize(Tensor &A, Tensor &B);\012		static bool sameRows(Tensor &A, Tensor &B);\012		static bool sameCols(Tensor &A, Tensor &B);\012		static void flopSize(Tensor *lhs, Tensor *rhs);\012		\012};\012\012\012#endif"}];
var alpha_viewer=false;